{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "ï»¿import os\n",
    "import sys\n",
    "import h5py\n",
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import scipy\n",
    "import pickle\n",
    "import imagesize\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "comment_questions": false
   },
   "outputs": [],
   "source": [
    "def init(mdlParams_):\n",
    "    if Path('mdlParams.pkl').exists():\n",
    "        mdlParams = pd.read_pickle('mdlParams.pkl')\n",
    "        return mdlParams\n",
    "    mdlParams = {}\n",
    "    # Save summaries and model here\n",
    "    mdlParams['saveDir'] = mdlParams_['pathBase']+'/out/'\n",
    "    # Data is loaded from here\n",
    "    mdlParams['dataDir'] = mdlParams_['pathBase']+'/data'\n",
    "\n",
    "    ### Model Selection ###\n",
    "    mdlParams['model_type'] = 'efficientnet-b0'\n",
    "    mdlParams['dataset_names'] = ['full'] #['official']#,'sevenpoint_rez3_ll']\n",
    "    mdlParams['file_ending'] = '.jpg'\n",
    "    mdlParams['exclude_inds'] = False\n",
    "    mdlParams['same_sized_crops'] = False\n",
    "    mdlParams['multiCropEval'] = 9\n",
    "    mdlParams['var_im_size'] = False\n",
    "    mdlParams['orderedCrop'] = False\n",
    "    mdlParams['voting_scheme'] = 'average'    \n",
    "    mdlParams['classification'] = True\n",
    "    mdlParams['balance_classes'] = 2\n",
    "    mdlParams['extra_fac'] = 1.0\n",
    "    mdlParams['numClasses'] = 2\n",
    "    mdlParams['no_c9_eval'] = True\n",
    "    mdlParams['numOut'] = mdlParams['numClasses']\n",
    "    mdlParams['numCV'] = 5\n",
    "    mdlParams['trans_norm_first'] = True\n",
    "    # Deterministic cropping\n",
    "    mdlParams['deterministic_eval'] = True\n",
    "    mdlParams['numCropPositions'] = 1\n",
    "    num_scales = 4\n",
    "    all_scales = [1.0,0.5,0.75,0.25,0.9,0.6,0.4]\n",
    "    mdlParams['cropScales'] = all_scales[:num_scales]\n",
    "    mdlParams['cropFlipping'] = 4\n",
    "    mdlParams['multiCropEval'] = mdlParams['numCropPositions']*len(mdlParams['cropScales'])*mdlParams['cropFlipping']\n",
    "    mdlParams['offset_crop'] = 0.2    \n",
    "    # Scale up for b1-b7\n",
    "    mdlParams['input_size'] = [224,224,3]     \n",
    "\n",
    "    ### Training Parameters ###\n",
    "    # Batch size\n",
    "    mdlParams['batchSize'] = 20#*len(mdlParams['numGPUs'])\n",
    "    # Initial learning rate\n",
    "    mdlParams['learning_rate'] = 0.00015#*len(mdlParams['numGPUs'])\n",
    "    # Lower learning rate after no improvement over 100 epochs\n",
    "    mdlParams['lowerLRAfter'] = 25\n",
    "    # If there is no validation set, start lowering the LR after X steps\n",
    "    mdlParams['lowerLRat'] = 50\n",
    "    # Divide learning rate by this value\n",
    "    mdlParams['LRstep'] = 5\n",
    "    # Maximum number of training iterations\n",
    "    mdlParams['training_steps'] = 20 #250\n",
    "    # Display error every X steps\n",
    "    mdlParams['display_step'] = 1\n",
    "    # Scale?\n",
    "    mdlParams['scale_targets'] = False\n",
    "    # Peak at test error during training? (generally, dont do this!)\n",
    "    mdlParams['peak_at_testerr'] = False\n",
    "    # Print trainerr\n",
    "    mdlParams['print_trainerr'] = True\n",
    "    # Subtract trainset mean?\n",
    "    mdlParams['subtract_set_mean'] = False\n",
    "    mdlParams['setMean'] = np.array([0.0, 0.0, 0.0])   \n",
    "    mdlParams['setStd'] = np.array([1.0, 1.0, 1.0])   \n",
    "\n",
    "    # Data AUG\n",
    "    #mdlParams['full_color_distort'] = True\n",
    "    mdlParams['autoaugment'] = False     \n",
    "    mdlParams['flip_lr_ud'] = True\n",
    "    mdlParams['full_rot'] = 180\n",
    "    mdlParams['scale'] = (0.8,1.2)\n",
    "    mdlParams['shear'] = 10\n",
    "    mdlParams['cutout'] = 16\n",
    "    \n",
    "    # Meta settings\n",
    "    mdlParams['meta_features'] = ['age_num','sex_oh','loc_oh']\n",
    "    mdlParams['meta_feature_sizes'] = [1,8,2]\n",
    "    mdlParams['encode_nan'] = False\n",
    "    mdlParams['model_load_path'] = '/out/2020.test_effb0_rr'\n",
    "    mdlParams['fc_layers_before'] = [256,256]\n",
    "    mdlParams['fc_layers_after'] = [1024]\n",
    "    mdlParams['freeze_cnn'] = True\n",
    "    mdlParams['learning_rate_meta'] = 0.00001\n",
    "    # each feature is set to missing with this prob\n",
    "    mdlParams['drop_augment'] = 0.1\n",
    "    mdlParams['dropout_meta'] = 0.4\n",
    "    mdlParams['scale_features'] = True\n",
    "\n",
    "    ### Data ###\n",
    "    mdlParams['preload'] = False\n",
    "    # Labels first\n",
    "    # Targets, as dictionary, indexed by im file name\n",
    "    mdlParams['labels_dict'] = {}\n",
    "    path1 = mdlParams['dataDir'] + '/labels/'\n",
    "     # All sets\n",
    "    allSets = glob(path1 + '*/')   \n",
    "    # Go through all sets\n",
    "    for i in range(len(allSets)):\n",
    "        # Check if want to include this dataset\n",
    "        foundSet = False\n",
    "        for j in range(len(mdlParams['dataset_names'])):\n",
    "            if mdlParams['dataset_names'][j] in allSets[i]:\n",
    "                foundSet = True\n",
    "        if not foundSet:\n",
    "            continue                \n",
    "        # Find csv file\n",
    "        files = sorted(glob(allSets[i]+'*'))\n",
    "        for j in range(len(files)):\n",
    "            if 'csv' in files[j]:\n",
    "                break\n",
    "        # Load csv file\n",
    "        with open(files[j], newline='') as csvfile:\n",
    "            labels_str = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "            for row in labels_str:\n",
    "                if 'image_id' == row[0]:\n",
    "                    continue\n",
    "                #if 'ISIC' in row[0] and '_downsampled' in row[0]:\n",
    "                #    print(row[0])\n",
    "                if row[0] + '_downsampled' in mdlParams['labels_dict']:\n",
    "                    print(\"removed\",row[0] + '_downsampled')\n",
    "                    continue\n",
    "                if mdlParams['numClasses'] == 2:\n",
    "                    mdlParams['labels_dict'][row[0]] = np.array([int(float(row[1])),int(float(row[2]))])                    \n",
    "                if mdlParams['numClasses'] == 7:\n",
    "                    mdlParams['labels_dict'][row[0]] = np.array([int(float(row[1])),int(float(row[2])),int(float(row[3])),int(float(row[4])),int(float(row[5])),int(float(row[6])),int(float(row[7]))])\n",
    "                elif mdlParams['numClasses'] == 8:\n",
    "                    if len(row) < 9 or row[8] == '':\n",
    "                        class_8 = 0\n",
    "                    else:\n",
    "                        class_8 = int(float(row[8]))\n",
    "                    mdlParams['labels_dict'][row[0]] = np.array([int(float(row[1])),int(float(row[2])),int(float(row[3])),int(float(row[4])),int(float(row[5])),int(float(row[6])),int(float(row[7])),class_8])\n",
    "                elif mdlParams['numClasses'] == 9:\n",
    "                    if len(row) < 9 or row[8] == '':\n",
    "                        class_8 = 0\n",
    "                    else:\n",
    "                        class_8 = int(float(row[8]))  \n",
    "                    if len(row) < 10 or row[9] == '':\n",
    "                        class_9 = 0\n",
    "                    else:\n",
    "                        class_9 = int(float(row[9]))                                           \n",
    "                    mdlParams['labels_dict'][row[0]] = np.array([int(float(row[1])),int(float(row[2])),int(float(row[3])),int(float(row[4])),int(float(row[5])),int(float(row[6])),int(float(row[7])),class_8,class_9])\n",
    "    # Save all im paths here\n",
    "    mdlParams['im_paths'] = []\n",
    "    mdlParams['labels_list'] = []\n",
    "    # Define the sets\n",
    "    path1 = mdlParams['dataDir'] + '/images/'\n",
    "    # All sets\n",
    "    allSets = sorted(glob(path1 + '*/'))\n",
    "    # Ids which name the folders\n",
    "    # Make official first datasets\n",
    "    for i in range(len(allSets)):\n",
    "        if mdlParams['dataset_names'][0] in allSets[i]:\n",
    "            temp = allSets[i]\n",
    "            allSets.remove(allSets[i])\n",
    "            allSets.insert(0, temp)\n",
    "    print(allSets)        \n",
    "    # Set of keys, for marking old HAM10000\n",
    "    mdlParams['key_list'] = []\n",
    "    if mdlParams['exclude_inds']:\n",
    "        with open(mdlParams['saveDir'] + 'indices_exclude.pkl','rb') as f:\n",
    "            indices_exclude = pickle.load(f)          \n",
    "        exclude_list = []    \n",
    "    for i in range(len(allSets)):\n",
    "        # All files in that set\n",
    "        files = sorted(glob(allSets[i]+'*'))\n",
    "        # Check if there is something in there, if not, discard\n",
    "        if len(files) == 0:\n",
    "            continue\n",
    "        # Check if want to include this dataset\n",
    "        foundSet = False\n",
    "        for j in range(len(mdlParams['dataset_names'])):\n",
    "            if mdlParams['dataset_names'][j] in allSets[i]:\n",
    "                foundSet = True\n",
    "        if not foundSet:\n",
    "            continue                    \n",
    "        for j in tqdm(range(len(files))):\n",
    "            if '.jpg' in files[j] or '.jpeg' in files[j] or '.JPG' in files[j] or '.JPEG' in files[j] or '.png' in files[j] or '.PNG' in files[j]:                \n",
    "                # Add according label, find it first\n",
    "                found_already = False\n",
    "                for key in mdlParams['labels_dict']:\n",
    "                    if key + mdlParams['file_ending'] in files[j]:\n",
    "                        if found_already:\n",
    "                            print(\"Found already:\",key,files[j])                     \n",
    "                        mdlParams['key_list'].append(key)\n",
    "                        mdlParams['labels_list'].append(mdlParams['labels_dict'][key])\n",
    "                        found_already = True\n",
    "                if found_already:\n",
    "                    mdlParams['im_paths'].append(files[j])     \n",
    "                    if mdlParams['exclude_inds']:\n",
    "                        for key in indices_exclude:\n",
    "                            if key in files[j]:\n",
    "                                exclude_list.append(indices_exclude[key])                                       \n",
    "    # Convert label list to array\n",
    "    mdlParams['labels_array'] = np.array(mdlParams['labels_list'])\n",
    "    print(np.mean(mdlParams['labels_array'],axis=0))        \n",
    "    # Create indices list with HAM10000 only\n",
    "    mdlParams['HAM10000_inds'] = []\n",
    "    HAM_START = 24306\n",
    "    HAM_END = 34320\n",
    "    for j in range(len(mdlParams['key_list'])):\n",
    "        try:\n",
    "            curr_id = [int(s) for s in re.findall(r'\\d+',mdlParams['key_list'][j])][-1]\n",
    "        except:\n",
    "            continue\n",
    "        if curr_id >= HAM_START and curr_id <= HAM_END:\n",
    "            mdlParams['HAM10000_inds'].append(j)\n",
    "    mdlParams['HAM10000_inds'] = np.array(mdlParams['HAM10000_inds'])    \n",
    "    print(\"Len ham\",len(mdlParams['HAM10000_inds']))   \n",
    "    # Perhaps preload images\n",
    "    if mdlParams['preload']:\n",
    "        mdlParams['images_array'] = np.zeros([len(mdlParams['im_paths']),mdlParams['input_size_load'][0],mdlParams['input_size_load'][1],mdlParams['input_size_load'][2]],dtype=np.uint8)\n",
    "        for i in range(len(mdlParams['im_paths'])):\n",
    "            x = scipy.ndimage.imread(mdlParams['im_paths'][i])\n",
    "            #x = x.astype(np.float32)   \n",
    "            # Scale to 0-1 \n",
    "            #min_x = np.min(x)\n",
    "            #max_x = np.max(x)\n",
    "            #x = (x-min_x)/(max_x-min_x)\n",
    "            mdlParams['images_array'][i,:,:,:] = x\n",
    "            if i%1000 == 0:\n",
    "                print(i+1,\"images loaded...\")     \n",
    "    if mdlParams['subtract_set_mean']:\n",
    "        mdlParams['images_means'] = np.zeros([len(mdlParams['im_paths']),3])\n",
    "        for i in range(len(mdlParams['im_paths'])):\n",
    "            x = scipy.ndimage.imread(mdlParams['im_paths'][i])\n",
    "            x = x.astype(np.float32)   \n",
    "            # Scale to 0-1 \n",
    "            min_x = np.min(x)\n",
    "            max_x = np.max(x)\n",
    "            x = (x-min_x)/(max_x-min_x)\n",
    "            mdlParams['images_means'][i,:] = np.mean(x,(0,1))\n",
    "            if i%1000 == 0:\n",
    "                print(i+1,\"images processed for mean...\")         \n",
    "\n",
    "    ### Define Indices ###\n",
    "    # Just divide into 5 equally large sets\n",
    "    with open(mdlParams['saveDir'] + 'indices_isic2020.pkl','rb') as f:\n",
    "        indices = pickle.load(f)           \n",
    "    mdlParams['trainIndCV'] = indices['trainIndCV']\n",
    "    mdlParams['valIndCV'] = indices['valIndCV']\n",
    "    if mdlParams['exclude_inds']:\n",
    "        exclude_list = np.array(exclude_list)\n",
    "        all_inds = np.arange(len(mdlParams['im_paths']))\n",
    "        exclude_inds = all_inds[exclude_list.astype(bool)]\n",
    "        for i in range(len(mdlParams['trainIndCV'])):\n",
    "            mdlParams['trainIndCV'][i] = np.setdiff1d(mdlParams['trainIndCV'][i],exclude_inds)\n",
    "        for i in range(len(mdlParams['valIndCV'])):\n",
    "            mdlParams['valIndCV'][i] = np.setdiff1d(mdlParams['valIndCV'][i],exclude_inds)     \n",
    "    # Consider case with more than one set\n",
    "    if len(mdlParams['dataset_names']) > 1:\n",
    "        restInds = np.array(np.arange(25331,mdlParams['labels_array'].shape[0]))\n",
    "        for i in range(mdlParams['numCV']):\n",
    "            mdlParams['trainIndCV'][i] = np.concatenate((mdlParams['trainIndCV'][i],restInds))        \n",
    "    print(\"Train\")\n",
    "    for i in range(len(mdlParams['trainIndCV'])):\n",
    "        print(mdlParams['trainIndCV'][i].shape)\n",
    "    print(\"Val\")\n",
    "    for i in range(len(mdlParams['valIndCV'])):\n",
    "        print(mdlParams['valIndCV'][i].shape)    \n",
    "\n",
    "    # Use this for ordered multi crops\n",
    "    if mdlParams['orderedCrop']:\n",
    "        # Crop positions, always choose multiCropEval to be 4, 9, 16, 25, etc.\n",
    "        mdlParams['cropPositions'] = np.zeros([len(mdlParams['im_paths']),mdlParams['multiCropEval'],2],dtype=np.int64)\n",
    "        #mdlParams['imSizes'] = np.zeros([len(mdlParams['im_paths']),mdlParams['multiCropEval'],2],dtype=np.int64)\n",
    "        for u in range(len(mdlParams['im_paths'])):\n",
    "            height, width = imagesize.get(mdlParams['im_paths'][u])\n",
    "            if width < mdlParams['input_size'][0]:\n",
    "                height = int(mdlParams['input_size'][0]/float(width))*height\n",
    "                width = mdlParams['input_size'][0]\n",
    "            if height < mdlParams['input_size'][0]:\n",
    "                width = int(mdlParams['input_size'][0]/float(height))*width\n",
    "                height = mdlParams['input_size'][0]            \n",
    "            ind = 0\n",
    "            for i in range(np.int32(np.sqrt(mdlParams['multiCropEval']))):\n",
    "                for j in range(np.int32(np.sqrt(mdlParams['multiCropEval']))):\n",
    "                    mdlParams['cropPositions'][u,ind,0] = mdlParams['input_size'][0]/2+i*((width-mdlParams['input_size'][1])/(np.sqrt(mdlParams['multiCropEval'])-1))\n",
    "                    mdlParams['cropPositions'][u,ind,1] = mdlParams['input_size'][1]/2+j*((height-mdlParams['input_size'][0])/(np.sqrt(mdlParams['multiCropEval'])-1))\n",
    "                    #mdlParams['imSizes'][u,ind,0] = curr_im_size[0]\n",
    "\n",
    "                    ind += 1\n",
    "        # Sanity checks\n",
    "        #print(\"Positions\",mdlParams['cropPositions'])\n",
    "        # Test image sizes\n",
    "        height = mdlParams['input_size'][0]\n",
    "        width = mdlParams['input_size'][1]\n",
    "        for u in range(len(mdlParams['im_paths'])):\n",
    "            height_test, width_test = imagesize.get(mdlParams['im_paths'][u])\n",
    "            if width_test < mdlParams['input_size'][0]:\n",
    "                height_test = int(mdlParams['input_size'][0]/float(width_test))*height_test\n",
    "                width_test = mdlParams['input_size'][0]\n",
    "            if height_test < mdlParams['input_size'][0]:\n",
    "                width_test = int(mdlParams['input_size'][0]/float(height_test))*width_test\n",
    "                height_test = mdlParams['input_size'][0]                \n",
    "            test_im = np.zeros([width_test,height_test]) \n",
    "            for i in range(mdlParams['multiCropEval']):\n",
    "                im_crop = test_im[np.int32(mdlParams['cropPositions'][u,i,0]-height/2):np.int32(mdlParams['cropPositions'][u,i,0]-height/2)+height,np.int32(mdlParams['cropPositions'][u,i,1]-width/2):np.int32(mdlParams['cropPositions'][u,i,1]-width/2)+width]\n",
    "                if im_crop.shape[0] != mdlParams['input_size'][0]:\n",
    "                    print(\"Wrong shape\",im_crop.shape[0],mdlParams['im_paths'][u])    \n",
    "                if im_crop.shape[1] != mdlParams['input_size'][1]:\n",
    "                    print(\"Wrong shape\",im_crop.shape[1],mdlParams['im_paths'][u])      \n",
    "                    \n",
    "    pd.to_pickle(mdlParams, 'mdlParams.pkl')\n",
    "    \n",
    "    return mdlParams"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "comment_questions,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
