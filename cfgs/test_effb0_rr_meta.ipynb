{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import scipy\n",
    "import pickle\n",
    "import imagesize\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from data import BASE_PATH, ordered_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Base Path\n",
    "params['path_base'] = BASE_PATH\n",
    "## Save summaries and model here\n",
    "params['save_dir'] = params['path_base'] / 'out'\n",
    "## Data is loaded from here\n",
    "params['data_dir'] = params['path_base'] / 'data'\n",
    "## CV Indices\n",
    "params['indices'] = params['save_dir'] / 'indices_isic2020.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['model_type'] = 'efficientnet-b0'\n",
    "params['dataset_names'] = ['full']\n",
    "params['file_ending'] = '.jpg'\n",
    "params['input_size_load'] = [512, 512, 3]\n",
    "params['exclude_inds'] = False\n",
    "params['same_sized_crops'] = False\n",
    "params['multiCropEval'] = 9\n",
    "params['var_im_size'] = False\n",
    "params['orderedCrop'] = False\n",
    "params['voting_scheme'] = 'average'    \n",
    "params['classification'] = True\n",
    "params['balance_classes'] = 2\n",
    "params['extra_fac'] = 1.0\n",
    "params['numClasses'] = 2\n",
    "params['no_c9_eval'] = True\n",
    "params['numOut'] = params['numClasses']\n",
    "params['numCV'] = 5\n",
    "params['trans_norm_first'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deterministic cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['deterministic_eval'] = True\n",
    "params['numCropPositions'] = 1\n",
    "num_scales = 4\n",
    "all_scales = [1.0,0.5,0.75,0.25,0.9,0.6,0.4]\n",
    "params['cropScales'] = all_scales[:num_scales]\n",
    "params['cropFlipping'] = 4\n",
    "params['multiCropEval'] = params['numCropPositions']*len(params['cropScales'])*params['cropFlipping']\n",
    "params['offset_crop'] = 0.2    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale up for b1-b7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['input_size'] = [224,224,3]     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "comment_questions": false
   },
   "source": [
    "# Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "comment_questions": false
   },
   "outputs": [],
   "source": [
    "# Batch size\n",
    "params['batchSize'] = 20#*len(params['numGPUs'])\n",
    "# Initial learning rate\n",
    "params['learning_rate'] = 0.001#*len(params['numGPUs'])\n",
    "# Lower learning rate after no improvement over 100 epochs\n",
    "params['lowerLRAfter'] = 25\n",
    "# If there is no validation set, start lowering the LR after X steps\n",
    "params['lowerLRat'] = 50\n",
    "# Divide learning rate by this value\n",
    "params['LRstep'] = 5\n",
    "# Maximum number of training iterations\n",
    "params['training_steps'] = 40 #250\n",
    "# Display error every X steps\n",
    "params['display_step'] = 1\n",
    "# Scale?\n",
    "params['scale_targets'] = False\n",
    "# Peak at test error during training? (generally, dont do this!)\n",
    "params['peak_at_testerr'] = False\n",
    "# Print trainerr\n",
    "params['print_trainerr'] = True\n",
    "# Subtract trainset mean?\n",
    "params['subtract_set_mean'] = False\n",
    "params['setMean'] = np.array([0.0, 0.0, 0.0])   \n",
    "params['setStd'] = np.array([1.0, 1.0, 1.0])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data AUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params['full_color_distort'] = True\n",
    "params['autoaugment'] = False     \n",
    "params['flip_lr_ud'] = True\n",
    "params['full_rot'] = 180\n",
    "params['scale'] = (0.8,1.2)\n",
    "params['shear'] = 10\n",
    "params['cutout'] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['meta_features'] = ['age_num','sex_oh','loc_oh']\n",
    "params['meta_feature_sizes'] = [1,8,2]\n",
    "params['encode_nan'] = False\n",
    "params['model_load_path'] = '/out/2020.test_effb0_rr'\n",
    "params['fc_layers_before'] = [256,256]\n",
    "params['fc_layers_after'] = [1024]\n",
    "params['freeze_cnn'] = True\n",
    "params['learning_rate_meta'] = 0.00001\n",
    "# each feature is set to missing with this prob\n",
    "params['drop_augment'] = 0.1\n",
    "params['dropout_meta'] = 0.4\n",
    "params['scale_features'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "Check labels first \n",
    "img_name are the keys\n",
    "one-hot encoding targets as arrays are the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['preload'] = False\n",
    "params['labels_dict'] = {}\n",
    "all_sets = params['data_dir'] / 'labels'\n",
    "params['img_paths'] = []\n",
    "params['labels_list'] = []\n",
    "params['key_list'] = []\n",
    "img_dirs = params['data_dir'] / 'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/clouderizer/melanoma/code/data/labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-98f4f6cfb7af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Go through all sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_sets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffix\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/pathlib.py\u001b[0m in \u001b[0;36miterdir\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'..'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                 \u001b[0;31m# Yielding a path object for these makes little sense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/pathlib.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(pathobj, *args)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mstrfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/clouderizer/melanoma/code/data/labels'"
     ]
    }
   ],
   "source": [
    "# Go through all sets\n",
    "for p in all_sets.iterdir():\n",
    "    if p.is_dir() and p.name in params['dataset_names']:\n",
    "        for file in p.iterdir():\n",
    "            if file.suffix == '.csv':\n",
    "                df = pd.read_csv(file)\n",
    "                keys = df.image_id.values\n",
    "                targets = df.drop('image_id', axis=1).values\n",
    "                params['labels_dict'].update(dict(zip(keys, targets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0f1610ea8b12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meta_dict'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mall_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data_dir'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'meta_data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_meta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "params['meta_dict'] = {}\n",
    "all_meta = params['data_dir'] / 'meta_data'\n",
    "for p in all_meta.iterdir():\n",
    "    if p.is_dir() and p.name in params['dataset_names']:\n",
    "        for file in p.iterdir():\n",
    "            if file.suffix == '.pkl':\n",
    "                with open(str(file), 'rb') as f:\n",
    "                    meta_data = pickle.load(f)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_dir in img_dirs.iterdir():\n",
    "    if img_dir.is_dir():\n",
    "        params['img_paths'].extend([img for img in img_dir.iterdir() if img.suffix.lower() in ('.jpg', '.jpeg', '.png')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in params['img_paths']:\n",
    "    if img.stem in params['labels_dict']:\n",
    "        params['key_list'].append(img.stem)\n",
    "        params['labels_list'].append(params['labels_dict'][img.stem])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert label list to array\n",
    "params['labels_array'] = np.array(params['labels_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perhaps preload images\n",
    "if params['preload']:\n",
    "    params['images_array'] = np.zeros([len(params['im_paths']),params['input_size_load'][0],params['input_size_load'][1],params['input_size_load'][2]],dtype=np.uint8)\n",
    "    for i in range(len(params['img_paths'])):\n",
    "        x = scipy.ndimage.imread(params['img_paths'][i])\n",
    "        #x = x.astype(np.float32)   \n",
    "        # Scale to 0-1 \n",
    "        #min_x = np.min(x)\n",
    "        #max_x = np.max(x)\n",
    "        #x = (x-min_x)/(max_x-min_x)\n",
    "        params['images_array'][i,:,:,:] = x\n",
    "        if i%1000 == 0:\n",
    "            print(i+1,\"images loaded...\")   \n",
    "        break\n",
    "\n",
    "if params['subtract_set_mean']:\n",
    "    params['images_means'] = np.zeros([len(params['im_paths']),3])\n",
    "    for i in range(len(params['im_paths'])):\n",
    "        x = scipy.ndimage.imread(params['im_paths'][i])\n",
    "        x = x.astype(np.float32)   \n",
    "        # Scale to 0-1 \n",
    "        min_x = np.min(x)\n",
    "        max_x = np.max(x)\n",
    "        x = (x-min_x)/(max_x-min_x)\n",
    "        params['images_means'][i,:] = np.mean(x,(0,1))\n",
    "        if i%1000 == 0:\n",
    "            print(i+1,\"images processed for mean...\")         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Indices ###\n",
    "# Just divide into 5 equally large sets\n",
    "with open(str(params['indices']), 'rb') as f:\n",
    "    indices = pickle.load(f)           \n",
    "params['trainIndCV'] = indices['trainIndCV']\n",
    "params['valIndCV'] = indices['valIndCV']\n",
    "if params['exclude_inds']:\n",
    "    exclude_list = np.array(exclude_list)\n",
    "    all_inds = np.arange(len(params['img_paths']))\n",
    "    exclude_inds = all_inds[exclude_list.astype(bool)]\n",
    "    for i in range(len(params['trainIndCV'])):\n",
    "        params['trainIndCV'][i] = np.setdiff1d(params['trainIndCV'][i],exclude_inds)\n",
    "    for i in range(len(params['valIndCV'])):\n",
    "        params['valIndCV'][i] = np.setdiff1d(params['valIndCV'][i],exclude_inds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "(45780,)\n",
      "(45824,)\n",
      "(45912,)\n",
      "(45662,)\n",
      "(45718,)\n",
      "Val\n",
      "(11444,)\n",
      "(11400,)\n",
      "(11312,)\n",
      "(11562,)\n",
      "(11506,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train\")\n",
    "for i in range(len(params['trainIndCV'])):\n",
    "    print(params['trainIndCV'][i].shape)\n",
    "print(\"Val\")\n",
    "for i in range(len(params['valIndCV'])):\n",
    "    print(params['valIndCV'][i].shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this for ordered multi crops\n",
    "if params['orderedCrop']:\n",
    "    params = ordered_crop(params)    \n",
    "pd.to_pickle(params, 'params_rr_meta.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "comment_questions,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
