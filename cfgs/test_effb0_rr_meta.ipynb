{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import scipy\n",
    "import pickle\n",
    "import imagesize\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from base import BASE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Base Path\n",
    "params['path_base'] = BASE_PATH\n",
    "## Save summaries and model here\n",
    "params['save_dir'] = params['path_base'] / 'out'\n",
    "## Data is loaded from here\n",
    "params['data_dir'] = params['path_base'] / 'data'\n",
    "## CV Indices\n",
    "params['indices'] = params['save_dir'] / 'indices_isic2020.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['model_type'] = 'efficientnet-b0'\n",
    "params['dataset_names'] = ['full']\n",
    "params['file_ending'] = '.jpg'\n",
    "params['input_size_load'] = [512, 512, 3]\n",
    "params['exclude_inds'] = False\n",
    "params['same_sized_crops'] = False\n",
    "params['multiCropEval'] = 9\n",
    "params['var_im_size'] = False\n",
    "params['orderedCrop'] = False\n",
    "params['voting_scheme'] = 'average'    \n",
    "params['classification'] = True\n",
    "params['balance_classes'] = 2\n",
    "params['extra_fac'] = 1.0\n",
    "params['numClasses'] = 2\n",
    "params['no_c9_eval'] = True\n",
    "params['numOut'] = params['numClasses']\n",
    "params['numCV'] = 5\n",
    "params['trans_norm_first'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deterministic cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['deterministic_eval'] = True\n",
    "params['numCropPositions'] = 1\n",
    "num_scales = 4\n",
    "all_scales = [1.0,0.5,0.75,0.25,0.9,0.6,0.4]\n",
    "params['cropScales'] = all_scales[:num_scales]\n",
    "params['cropFlipping'] = 4\n",
    "params['multiCropEval'] = params['numCropPositions']*len(params['cropScales'])*params['cropFlipping']\n",
    "params['offset_crop'] = 0.2    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale up for b1-b7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['input_size'] = [224,224,3]     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "comment_questions": false
   },
   "source": [
    "# Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "comment_questions": false
   },
   "outputs": [],
   "source": [
    "# Batch size\n",
    "params['batchSize'] = 20#*len(params['numGPUs'])\n",
    "# Initial learning rate\n",
    "params['learning_rate'] = 0.001#*len(params['numGPUs'])\n",
    "# Lower learning rate after no improvement over 100 epochs\n",
    "params['lowerLRAfter'] = 25\n",
    "# If there is no validation set, start lowering the LR after X steps\n",
    "params['lowerLRat'] = 50\n",
    "# Divide learning rate by this value\n",
    "params['LRstep'] = 5\n",
    "# Maximum number of training iterations\n",
    "params['training_steps'] = 40 #250\n",
    "# Display error every X steps\n",
    "params['display_step'] = 1\n",
    "# Scale?\n",
    "params['scale_targets'] = False\n",
    "# Peak at test error during training? (generally, dont do this!)\n",
    "params['peak_at_testerr'] = False\n",
    "# Print trainerr\n",
    "params['print_trainerr'] = True\n",
    "# Subtract trainset mean?\n",
    "params['subtract_set_mean'] = False\n",
    "params['setMean'] = np.array([0.0, 0.0, 0.0])   \n",
    "params['setStd'] = np.array([1.0, 1.0, 1.0])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data AUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params['full_color_distort'] = True\n",
    "params['autoaugment'] = False     \n",
    "params['flip_lr_ud'] = True\n",
    "params['full_rot'] = 180\n",
    "params['scale'] = (0.8,1.2)\n",
    "params['shear'] = 10\n",
    "params['cutout'] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['meta_features'] = ['age_num','sex_oh','loc_oh']\n",
    "params['meta_feature_sizes'] = [1,8,2]\n",
    "params['encode_nan'] = False\n",
    "params['model_load_path'] = '/out/2020.test_effb0_rr'\n",
    "params['fc_layers_before'] = [256,256]\n",
    "params['fc_layers_after'] = [1024]\n",
    "params['freeze_cnn'] = True\n",
    "params['learning_rate_meta'] = 0.00001\n",
    "# each feature is set to missing with this prob\n",
    "params['drop_augment'] = 0.1\n",
    "params['dropout_meta'] = 0.4\n",
    "params['scale_features'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "Check labels first \n",
    "img_name are the keys\n",
    "one-hot encoding targets as arrays are the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['preload'] = False\n",
    "params['labels_dict'] = {}\n",
    "all_sets = params['data_dir'] / 'labels'\n",
    "params['img_paths'] = []\n",
    "params['labels_list'] = []\n",
    "params['key_list'] = []\n",
    "img_dirs = params['data_dir'] / 'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through all sets\n",
    "for p in all_sets.iterdir():\n",
    "    if p.is_dir() and p.name in params['dataset_names']:\n",
    "        for file in p.iterdir():\n",
    "            if file.suffix == '.csv':\n",
    "                df = pd.read_csv(file)\n",
    "                keys = df.image_id.values\n",
    "                targets = df.drop('image_id', axis=1).values\n",
    "                params['labels_dict'].update(dict(zip(keys, targets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_dir in img_dirs.iterdir():\n",
    "    if img_dir.is_dir():\n",
    "        params['img_paths'].extend([img for img in img_dir.iterdir() if img.suffix.lower() in ('.jpg', '.jpeg', '.png')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in params['img_paths']:\n",
    "    if img.stem in params['labels_dict']:\n",
    "        params['key_list'].append(img.stem)\n",
    "        params['labels_list'].append(params['labels_dict'][img.stem])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert label list to array\n",
    "params['labels_array'] = np.array(params['labels_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perhaps preload images\n",
    "if params['preload']:\n",
    "    params['images_array'] = np.zeros([len(params['im_paths']),params['input_size_load'][0],params['input_size_load'][1],params['input_size_load'][2]],dtype=np.uint8)\n",
    "    for i in range(len(params['img_paths'])):\n",
    "        x = scipy.ndimage.imread(params['img_paths'][i])\n",
    "        #x = x.astype(np.float32)   \n",
    "        # Scale to 0-1 \n",
    "        #min_x = np.min(x)\n",
    "        #max_x = np.max(x)\n",
    "        #x = (x-min_x)/(max_x-min_x)\n",
    "        params['images_array'][i,:,:,:] = x\n",
    "        if i%1000 == 0:\n",
    "            print(i+1,\"images loaded...\")   \n",
    "        break\n",
    "\n",
    "if params['subtract_set_mean']:\n",
    "    params['images_means'] = np.zeros([len(params['im_paths']),3])\n",
    "    for i in range(len(params['im_paths'])):\n",
    "        x = scipy.ndimage.imread(params['im_paths'][i])\n",
    "        x = x.astype(np.float32)   \n",
    "        # Scale to 0-1 \n",
    "        min_x = np.min(x)\n",
    "        max_x = np.max(x)\n",
    "        x = (x-min_x)/(max_x-min_x)\n",
    "        params['images_means'][i,:] = np.mean(x,(0,1))\n",
    "        if i%1000 == 0:\n",
    "            print(i+1,\"images processed for mean...\")         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Indices ###\n",
    "# Just divide into 5 equally large sets\n",
    "with open(str(params['indices']), 'rb') as f:\n",
    "    indices = pickle.load(f)           \n",
    "params['trainIndCV'] = indices['trainIndCV']\n",
    "params['valIndCV'] = indices['valIndCV']\n",
    "if params['exclude_inds']:\n",
    "    exclude_list = np.array(exclude_list)\n",
    "    all_inds = np.arange(len(params['img_paths']))\n",
    "    exclude_inds = all_inds[exclude_list.astype(bool)]\n",
    "    for i in range(len(params['trainIndCV'])):\n",
    "        params['trainIndCV'][i] = np.setdiff1d(params['trainIndCV'][i],exclude_inds)\n",
    "    for i in range(len(params['valIndCV'])):\n",
    "        params['valIndCV'][i] = np.setdiff1d(params['valIndCV'][i],exclude_inds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "(45780,)\n",
      "(45824,)\n",
      "(45912,)\n",
      "(45662,)\n",
      "(45718,)\n",
      "Val\n",
      "(11444,)\n",
      "(11400,)\n",
      "(11312,)\n",
      "(11562,)\n",
      "(11506,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train\")\n",
    "for i in range(len(params['trainIndCV'])):\n",
    "    print(params['trainIndCV'][i].shape)\n",
    "print(\"Val\")\n",
    "for i in range(len(params['valIndCV'])):\n",
    "    print(params['valIndCV'][i].shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_crop(params):\n",
    "    # Crop positions, always choose multiCropEval to be 4, 9, 16, 25, etc.\n",
    "    params['cropPositions'] = np.zeros([len(params['img_paths']),params['multiCropEval'],2],dtype=np.int64)\n",
    "    #params['imSizes'] = np.zeros([len(params['im_paths']),params['multiCropEval'],2],dtype=np.int64)\n",
    "    for u, img in enumerate(params['img_paths'].iterdir()):\n",
    "        height, width = imagesize.get(img)\n",
    "        if width < params['input_size'][0]:\n",
    "            height = int(params['input_size'][0]/float(width))*height\n",
    "            width = params['input_size'][0]\n",
    "        if height < params['input_size'][0]:\n",
    "            width = int(params['input_size'][0]/float(height))*width\n",
    "            height = params['input_size'][0]            \n",
    "        ind = 0\n",
    "        for i in range(np.int32(np.sqrt(params['multiCropEval']))):\n",
    "            for j in range(np.int32(np.sqrt(params['multiCropEval']))):\n",
    "                params['cropPositions'][u,ind,0] = params['input_size'][0]/2+i*((width-params['input_size'][1])/(np.sqrt(params['multiCropEval'])-1))\n",
    "                params['cropPositions'][u,ind,1] = params['input_size'][1]/2+j*((height-params['input_size'][0])/(np.sqrt(params['multiCropEval'])-1))\n",
    "                #params['imSizes'][u,ind,0] = curr_im_size[0]\n",
    "                ind += 1\n",
    "    # Sanity checks\n",
    "    #print(\"Positions\",params['cropPositions'])\n",
    "    # Test image sizes\n",
    "    height = params['input_size'][0]\n",
    "    width = params['input_size'][1]\n",
    "    for u, img in enumerate(params['img_paths'].iterdir()):\n",
    "        height_test, width_test = imagesize.get(img)\n",
    "        if width_test < params['input_size'][0]:\n",
    "            height_test = int(params['input_size'][0]/float(width_test))*height_test\n",
    "            width_test = params['input_size'][0]\n",
    "        if height_test < params['input_size'][0]:\n",
    "            width_test = int(params['input_size'][0]/float(height_test))*width_test\n",
    "            height_test = params['input_size'][0]                \n",
    "        test_im = np.zeros([width_test,height_test]) \n",
    "        for i in range(params['multiCropEval']):\n",
    "            im_crop = test_im[np.int32(params['cropPositions'][u,i,0]-height/2):np.int32(params['cropPositions'][u,i,0]-height/2)+height,np.int32(params['cropPositions'][u,i,1]-width/2):np.int32(params['cropPositions'][u,i,1]-width/2)+width]\n",
    "            if im_crop.shape[0] != params['input_size'][0]:\n",
    "                print(\"Wrong shape\",im_crop.shape[0],params['im_paths'][u])    \n",
    "            if im_crop.shape[1] != params['input_size'][1]:\n",
    "                print(\"Wrong shape\",im_crop.shape[1],params['im_paths'][u])\n",
    "                \n",
    "    return params   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this for ordered multi crops\n",
    "if params['orderedCrop']:\n",
    "    params = ordered_crop(params)\n",
    "    \n",
    "pd.to_pickle(params, 'params_rr_meta.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "comment_questions,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
