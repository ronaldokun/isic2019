{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "from data import *\n",
    "#from data_transforms import *\n",
    "from apex import amp\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from catalyst.data.sampler import BalanceClassSampler\n",
    "\n",
    "#CV2\n",
    "import cv2\n",
    "\n",
    "#Importing Tabnet\n",
    "from pytorch_tabnet.tab_network import TabNet\n",
    "\n",
    "import datetime\n",
    "from fastprogress import master_bar, progress_bar\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Categorical variables and their Indexes, embedding dimensions , number of classes each have\n",
    "df = pd.read_csv('/data/full/folds_13062020.csv')\n",
    "df_test =pd.read_csv('/data/full/test.csv')\n",
    "df_test['anatom_site_general_challenge'].fillna('unknown',inplace=True)\n",
    "df_test['target'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sex 3\n",
      "test sex 2\n",
      "train anatom_site_general_challenge 8\n",
      "test anatom_site_general_challenge 7\n"
     ]
    }
   ],
   "source": [
    "features = ['sex', 'age_approx', 'anatom_site_general_challenge'] \n",
    "cat = ['sex', 'anatom_site_general_challenge']\n",
    "target = 'target'\n",
    "\n",
    "categorical_columns = []\n",
    "\n",
    "for col in cat:    \n",
    "    print('train', col, df[col].nunique())\n",
    "    print('test', col, df_test[col].nunique())\n",
    "    l_enc = LabelEncoder()\n",
    "    df[col] = l_enc.fit_transform(df[col].values)\n",
    "    df_test[col] = l_enc.transform(df_test[col].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelanomaDataset(Dataset):  \n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, \n",
    "                 imfolder: (str, Path), \n",
    "                 train: bool = True, \n",
    "                 transforms = None, \n",
    "                 meta_features = None):\n",
    "        \"\"\"\n",
    "        Class initialization\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame with data description\n",
    "            imfolder (str): folder with images\n",
    "            train (bool): flag of whether a training dataset is being initialized or testing one\n",
    "            transforms: image transformation method to be applied\n",
    "            meta_features (list): list of features with meta information, such as sex and age\n",
    "            \n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.imfolder = imfolder\n",
    "        self.transforms = transforms\n",
    "        self.train = train\n",
    "        self.meta_features = meta_features\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        im_path = Path(f\"{self.imfolder}/{self.df.iloc[index]['image_name']}.jpg\")\n",
    "        x = cv2.imread(str(im_path))\n",
    "        meta = torch.tensor(self.df.iloc[index][self.meta_features].values, dtype=torch.float)\n",
    "\n",
    "        if self.transforms:\n",
    "            x = self.transforms(x)\n",
    "            \n",
    "        if self.train:\n",
    "            y = self.df.iloc[index]['target']\n",
    "            y_meta = self.one_hot(2, y)                    \n",
    "            return {'image': x,\n",
    "                    'label': y,\n",
    "                    'features': meta,\n",
    "                    'target': y_meta}\n",
    "        else:\n",
    "            return {'image': x,\n",
    "                    'label': None,\n",
    "                    'features': meta,\n",
    "                    'target': None}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "                       \n",
    "    @staticmethod\n",
    "    def one_hot(size, target):\n",
    "        tensor = torch.zeros(size, dtype=torch.float32)\n",
    "        tensor[target] = 1.\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTabnet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim,n_d=8, n_a=8,n_steps=3, gamma=1.3,\n",
    "                cat_idxs=[], cat_dims=[3,8], cat_emb_dim=[3,5],n_independent=2, n_shared=2,\n",
    "                momentum=0.02,mask_type=\"sparsemax\"):\n",
    "        \n",
    "        super(CustomTabnet, self).__init__()\n",
    "        self.tabnet = TabNet(input_dim=input_dim,output_dim=output_dim, n_d=n_d, n_a=n_a,n_steps=n_steps, gamma=gamma,\n",
    "                             cat_idxs=cat_idxs, cat_dims=cat_dims, cat_emb_dim=cat_emb_dim,n_independent=n_independent,\n",
    "                             n_shared=n_shared, momentum=momentum,mask_type=\"sparsemax\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.tabnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabnet = CustomTabnet(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tabnet.tabnet.modules())[-1].in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to /content/.cache/torch/hub/checkpoints/efficientnet-b0-355c32eb.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ebb38bcdec4e80acff1abe7e4cdc44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21388428.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "net = EfficientNet.from_pretrained('efficientnet-b0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Effnet(nn.Module):\n",
    "    def __init__(self, arch, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.arch = arch\n",
    "        self.arch._fc = nn.Linear(in_features=1280, out_features=64, bias=True)\n",
    "        self.tab = CustomTabnet(input_dim, output_dim)\n",
    "        self.tab = nn.Sequential(*list(self.tab.modules())[:-1])\n",
    "        self.ouput = nn.Linear(64 + 8, 1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        No sigmoid in forward because we are going to use BCEWithLogitsLoss\n",
    "        Which applies sigmoid for us when calculating a loss\n",
    "        \"\"\"\n",
    "        x, meta = inputs['image'], inputs['features']\n",
    "        cnn_features = self.arch(x)\n",
    "        meta_features = self.tab(meta)\n",
    "        features = torch.cat((cnn_features, meta_features), dim=1)\n",
    "        output = self.ouput(features)\n",
    "        return output \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = MelanomaDataset(df=test_df,\n",
    "                       imfolder=TEST, \n",
    "                       train=False,\n",
    "                       transforms=train_transform,  # For TTA\n",
    "                       meta_features=meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "epochs = 15  # Number of epochs to run\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "TTA = 3 # Test Time Augmentation rounds\n",
    "\n",
    "oof = np.zeros((len(train_df), 1))  # Out Of Fold predictions\n",
    "preds = torch.zeros((len(test), 1), dtype=torch.float32, device=device)  # Predictions for test test\n",
    "\n",
    "skf = KFold(n_splits=5, shuffle=True, random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Fold 4 ====================\n",
      "Loaded pretrained weights for efficientnet-b1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2' class='' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      13.33% [2/15 08:45<56:54]\n",
       "    </div>\n",
       "    \n",
       "Epoch 001: | Loss: 39.428 | Train acc: 0.489 | Val acc: 0.982 | Val roc_auc: 0.799 | Training time: 0:04:22<p>Epoch 002: | Loss: 34.553 | Train acc: 0.490 | Val acc: 0.982 | Val roc_auc: 0.825 | Training time: 0:04:22<p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='99' class='' max='408' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      24.26% [99/408 00:55<02:53 7.3790]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fold,(idxT, idxV) in enumerate(list(skf.split(np.arange(15)))[3:], 4):\n",
    "    print('=' * 20, 'Fold', fold, '=' * 20)\n",
    "    \n",
    "    train_idx = train_df.loc[train_df['fold'].isin(idxT)].index\n",
    "    val_idx = train_df.loc[train_df['fold'].isin(idxV)].index\n",
    "    \n",
    "    \n",
    "    model_path = f'/out/model_{fold}.pth'  # Path and filename to save model to\n",
    "    best_val = 0  # Best validation score within this fold\n",
    "    patience = es_patience  # Current patience counter\n",
    "    arch = EfficientNet.from_pretrained('efficientnet-b1')\n",
    "    model = Effnet(arch=arch, n_meta_features=len(meta_features))  # New model for each fold\n",
    "    if Path(model_path).exists():\n",
    "        inference = True\n",
    "        \n",
    "    model = model.to(device)\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optim, mode='max', patience=1, verbose=True, factor=0.2)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    train = MelanomaDataset(df=train_df.iloc[train_idx].reset_index(drop=True), \n",
    "                            imfolder=TRAIN, \n",
    "                            train=True, \n",
    "                            transforms=train_transform,\n",
    "                            meta_features=meta_features)\n",
    "    val = MelanomaDataset(df=train_df.iloc[val_idx].reset_index(drop=True), \n",
    "                            imfolder=TRAIN, \n",
    "                            train=True, \n",
    "                            transforms=test_transform,\n",
    "                            meta_features=meta_features)\n",
    "    \n",
    "    train_loader = DataLoader(dataset=train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(dataset=val, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    test_loader = DataLoader(dataset=test, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    mb = master_bar(range(epochs))\n",
    "\n",
    "    if not inference:\n",
    "    \n",
    "        for epoch in mb:\n",
    "            start_time = time.time()\n",
    "            correct = 0\n",
    "            epoch_loss = 0\n",
    "            model.train()\n",
    "            \n",
    "            for x, y in progress_bar(train_loader, parent=mb, total=int(len(train)/ 64)):\n",
    "                x[0] = torch.tensor(x[0], device=device, dtype=torch.float32)\n",
    "                x[1] = torch.tensor(x[1], device=device, dtype=torch.float32)\n",
    "                y = torch.tensor(y, device=device, dtype=torch.float32)\n",
    "                optim.zero_grad()\n",
    "                z = model(x)\n",
    "                loss = criterion(z, y.unsqueeze(1))\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "                pred = torch.round(torch.sigmoid(z))  # round off sigmoid to obtain predictions\n",
    "                correct += (pred.cpu() == y.cpu().unsqueeze(1)).sum().item()  # tracking number of correctly predicted samples\n",
    "                epoch_loss += loss.item()\n",
    "                mb.child.comment = f'{epoch_loss:.4f}'\n",
    "            train_acc = correct / len(train_idx)\n",
    "            \n",
    "            model.eval()  # switch model to the evaluation mode\n",
    "            val_preds = torch.zeros((len(val_idx), 1), dtype=torch.float32, device=device)\n",
    "            with torch.no_grad():  # Do not calculate gradient since we are only predicting\n",
    "                # Predicting on validation set\n",
    "                for j, (x_val, y_val) in progress_bar(enumerate(val_loader), parent=mb, total=int(len(val)/32)):\n",
    "                    x_val[0] = torch.tensor(x_val[0], device=device, dtype=torch.float32)\n",
    "                    x_val[1] = torch.tensor(x_val[1], device=device, dtype=torch.float32)\n",
    "                    y_val = torch.tensor(y_val, device=device, dtype=torch.float32)\n",
    "                    z_val = model(x_val)\n",
    "                    val_pred = torch.sigmoid(z_val)\n",
    "                    val_preds[j*val_loader.batch_size:j*val_loader.batch_size + x_val[0].shape[0]] = val_pred\n",
    "                val_acc = accuracy_score(train_df.iloc[val_idx]['target'].values, torch.round(val_preds.cpu()))\n",
    "                val_roc = roc_auc_score(train_df.iloc[val_idx]['target'].values, val_preds.cpu())\n",
    "                \n",
    "                mb.write('Epoch {:03}: | Loss: {:.3f} | Train acc: {:.3f} | Val acc: {:.3f} | Val roc_auc: {:.3f} | Training time: {}'.format(\n",
    "                epoch + 1, \n",
    "                epoch_loss, \n",
    "                train_acc, \n",
    "                val_acc, \n",
    "                val_roc, \n",
    "                str(datetime.timedelta(seconds=time.time() - start_time))[:7]))\n",
    "                \n",
    "                scheduler.step(val_roc)\n",
    "                    \n",
    "                if val_roc >= best_val:\n",
    "                    best_val = val_roc\n",
    "                    patience = es_patience  # Resetting patience since we have new best validation accuracy\n",
    "                    torch.save(model, model_path)  # Saving current best model\n",
    "                else:\n",
    "                    patience -= 1\n",
    "                    if patience == 0:\n",
    "                        print('Early stopping. Best Val roc_auc: {:.3f}'.format(best_val))\n",
    "                        break\n",
    "                \n",
    "    model = torch.load(model_path)  # Loading best model of this fold\n",
    "    model.eval()  # switch model to the evaluation mode\n",
    "    val_preds = torch.zeros((len(val_idx), 1), dtype=torch.float32, device=device)\n",
    "    with torch.no_grad():\n",
    "        # Predicting on validation set once again to obtain data for OOF\n",
    "        for j, (x_val, y_val) in progress_bar(enumerate(val_loader), total=int(len(val)/32)):\n",
    "            x_val[0] = torch.tensor(x_val[0], device=device, dtype=torch.float32)\n",
    "            x_val[1] = torch.tensor(x_val[1], device=device, dtype=torch.float32)\n",
    "            y_val = torch.tensor(y_val, device=device, dtype=torch.float32)\n",
    "            z_val = model(x_val)\n",
    "            val_pred = torch.sigmoid(z_val)\n",
    "            val_preds[j*val_loader.batch_size:j*val_loader.batch_size + x_val[0].shape[0]] = val_pred\n",
    "        oof[val_idx] = val_preds.cpu().numpy()\n",
    "        \n",
    "        # Predicting on test set\n",
    "        for _ in range(TTA):\n",
    "            for i, x_test in progress_bar(enumerate(test_loader), parent=mb, total=len(test)//32):\n",
    "                x_test[0] = torch.tensor(x_test[0], device=device, dtype=torch.float32)\n",
    "                x_test[1] = torch.tensor(x_test[1], device=device, dtype=torch.float32)\n",
    "                z_test = model(x_test)\n",
    "                z_test = torch.sigmoid(z_test)\n",
    "                preds[i*test_loader.batch_size:i*test_loader.batch_size + x_test[0].shape[0]] += z_test\n",
    "        preds /= TTA\n",
    "        \n",
    "    del train, val, train_loader, val_loader, x, y, x_val, y_val\n",
    "    gc.collect()\n",
    "    \n",
    "preds /= skf.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving OOF predictions so stacking would be easier\n",
    "pd.Series(oof.reshape(-1,)).to_csv('oof.csv', index=False)\n",
    "sub = pd.read_csv(DATA / 'sample_submission.csv')\n",
    "sub['target'] = preds.cpu().numpy().reshape(-1,)\n",
    "sub.to_csv('/out/img_meta_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c siim-isic-melanoma-classification -f submission.csv -m \"Melanoma Starter Image Size 384\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
