{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkQEDQA44qlC"
   },
   "source": [
    "# Melanoma classification with PyTorch Lightning\n",
    "\n",
    "Using EfficientNet on PyTorch Lightning, with its amazing hardware agnostic and mixed precision implementation.\n",
    "\n",
    "This is still work in progress, so please bear with me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ftZsAlKR4qlF"
   },
   "outputs": [],
   "source": [
    "fold_number = 2\n",
    "tta   = 20\n",
    "\n",
    "batch_size = {\n",
    "    'tpu': 10, # x8\n",
    "    'gpu': 16, # 10 without AMP\n",
    "    'cpu': 4,\n",
    "}\n",
    "\n",
    "arch = 'efficientnet-b5'\n",
    "resolution = 456  # orignal res for B5\n",
    "input_res  = 512\n",
    "\n",
    "lr = 8e-6   # * batch_size\n",
    "weight_decay = 2e-5\n",
    "pos_weight   = 3.2\n",
    "label_smoothing = 0.03\n",
    "\n",
    "max_epochs = 10\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade wandb\n",
    "!wandb login 6ff8d5e5bd920e68d1f76b574f1880278b4ac8d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oa7QSur04qlR"
   },
   "source": [
    "# Install modules\n",
    "\n",
    "Update PyTorch to enable its native support to Mixed Precision or XLA for TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRdfuFiR4qlf"
   },
   "source": [
    "# Hardware lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  5115  100  5115    0     0  78692      0 --:--:-- --:--:-- --:--:-- 78692\n",
      "Updating... This may take around 2 minutes.\n",
      "Updating TPU runtime to pytorch-nightly ...\n",
      "Found existing installation: torch 1.7.0a0+a53fdaa\n",
      "Uninstalling torch-1.7.0a0+a53fdaa:\n",
      "  Successfully uninstalled torch-1.7.0a0+a53fdaa\n",
      "Found existing installation: torchvision 0.8.0a0+7666252\n",
      "Uninstalling torchvision-0.8.0a0+7666252:\n",
      "  Successfully uninstalled torchvision-0.8.0a0+7666252\n",
      "Done updating TPU runtime\n",
      "Traceback (most recent call last):\n",
      "  File \"pytorch-xla-env-setup.py\", line 161, in <module>\n",
      "    run_setup(args)\n",
      "  File \"pytorch-xla-env-setup.py\", line 135, in run_setup\n",
      "    install_vm(version, args.apt_packages, is_root=not args.tpu)\n",
      "  File \"pytorch-xla-env-setup.py\", line 119, in install_vm\n",
      "  File \"/usr/lib/python3.6/subprocess.py\", line 289, in call\n",
      "    return p.wait(timeout=timeout)\n",
      "  File \"/usr/lib/python3.6/subprocess.py\", line 1477, in wait\n",
      "    (pid, sts) = self._try_wait(0)\n",
      "  File \"/usr/lib/python3.6/subprocess.py\", line 1424, in _try_wait\n",
      "    (pid, sts) = os.waitpid(self.pid, wait_flags)\n",
      "KeyboardInterrupt\n",
      "Caught CTRL-C (signal 2) - exiting\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import collections\n",
    "# from datetime import datetime, timedelta\n",
    "\n",
    "# if 'TPU_NAME' in os.environ.keys():\n",
    "    \n",
    "#     !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "#       python3 pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev\n",
    "\n",
    "#     os.environ[\"XRT_TPU_CONFIG\"] = \"tpu_worker;0;10.0.0.2:8470\"\n",
    "\n",
    "#     _VersionConfig = collections.namedtuple('_VersionConfig', 'wheels,server')\n",
    "#     VERSION = \"torch_xla==nightly\"\n",
    "#     CONFIG = {\n",
    "#         'torch_xla==nightly': _VersionConfig('nightly', 'XRT-dev{}'.format(\n",
    "#             (datetime.today() - timedelta(1)).strftime('%Y%m%d')))}[VERSION]\n",
    "\n",
    "#     DIST_BUCKET = 'gs://tpu-pytorch/wheels'\n",
    "#     TORCH_WHEEL = 'torch-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)\n",
    "#     TORCH_XLA_WHEEL = 'torch_xla-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)\n",
    "#     TORCHVISION_WHEEL = 'torchvision-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)\n",
    "\n",
    "#     !export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH\n",
    "#     !apt-get install libomp5 -y\n",
    "#     !apt-get install libopenblas-dev -y\n",
    "\n",
    "#     !pip3 uninstall -y torch torchvision\n",
    "#     !gsutil cp \"$DIST_BUCKET/$TORCH_WHEEL\" .\n",
    "#     !gsutil cp \"$DIST_BUCKET/$TORCH_XLA_WHEEL\" .\n",
    "#     !gsutil cp \"$DIST_BUCKET/$TORCHVISION_WHEEL\" .\n",
    "#     !pip3 install \"$TORCH_WHEEL\"\n",
    "#     !pip3 install \"$TORCH_XLA_WHEEL\"\n",
    "#     !pip3 install \"$TORCHVISION_WHEEL\"\n",
    "# else:\n",
    "#     print(f'No TPU Baby!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip3 install -U pip albumentations==0.4.5 PyYAML pytorch-lightning==0.8.5 efficientnet_pytorch\n",
    "# Update PyTorch to enable its native support to Mixed Precision\n",
    "#!pip3 install --pre torch==1.7.0.dev20200701+cu101 torchvision==0.8.0.dev20200701+cu101 -f https://download.pytorch.org/whl/nightly/cu101/torch_nightly.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true,
    "id": "t9FS-xGM4qlh",
    "outputId": "5802bc07-8b6e-4254-ac49-2139d11911f8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "num_workers = os.cpu_count()\n",
    "gpus = 1 if torch.cuda.is_available() else None\n",
    "\n",
    "try:\n",
    "    import torch_xla\n",
    "    import torch_xla.utils.utils as xu\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    import torch_xla.debug.metrics as met\n",
    "    import torch_xla.distributed.data_parallel as dp\n",
    "    import torch_xla.distributed.parallel_loader as pl\n",
    "    import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "    tpu_cores = 8 #xm.xrt_world_size()\n",
    "except:\n",
    "    tpu_cores = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true,
    "id": "t9FS-xGM4qlh",
    "outputId": "5802bc07-8b6e-4254-ac49-2139d11911f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_workers': 1, 'tpu_cores': 8, 'gpus': None, 'batch_size': 10, 'lr': 0.0006399999999999999}\n"
     ]
    }
   ],
   "source": [
    "if isinstance(batch_size, dict):\n",
    "    if tpu_cores:\n",
    "        batch_size = batch_size['tpu']\n",
    "        lr *= tpu_cores\n",
    "        num_workers = 1\n",
    "    elif gpus:\n",
    "        batch_size = batch_size['gpu']\n",
    "        # support for free Colab GPU's\n",
    "        if 'K80' in torch.cuda.get_device_name():\n",
    "            batch_size = batch_size//3\n",
    "        elif 'T4' in torch.cuda.get_device_name():\n",
    "            batch_size = int(batch_size * 0.66)\n",
    "    else:\n",
    "        batch_size = batch_size['cpu']\n",
    "\n",
    "lr *= batch_size\n",
    "\n",
    "print(dict(\n",
    "    num_workers=num_workers,\n",
    "    tpu_cores=tpu_cores,\n",
    "    gpus=gpus,\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "        )\n",
    "     )\n",
    "\n",
    "# check for torch's native mixed precision support (pt1.6+)\n",
    "if gpus and not hasattr(torch.cuda, \"amp\"):\n",
    "    try:\n",
    "        from apex import amp\n",
    "    except:\n",
    "        !git clone https://github.com/NVIDIA/apex  nv_apex\n",
    "        !pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./nv_apex\n",
    "        from apex import amp\n",
    "    # with PyTorch Lightning all you need to do now is set precision=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaoinaAu4qlu"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "id": "UFXXIDJt4qlv",
    "outputId": "b5e99e4c-016c-440c-e2f4-c3ed45ba50eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0a0+a53fdaa\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "from skimage import io\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from glob import glob\n",
    "import sklearn\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "from dataset import load_datasets\n",
    "from utils import get_train_transforms, get_valid_transforms, get_tta_transforms\n",
    "from data import *\n",
    "from pathlib import Path\n",
    "from fastprogress import progress_bar as tqdm\n",
    "SAVE_DIR = OUT / f'pl/fold_{fold_number}'\n",
    "SAVE_DIR.mkdir(exist_ok=True, parents=True)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6K-p9nPl4ql-"
   },
   "source": [
    "# Setup dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Dq3S8RAF4ql_",
    "outputId": "00122522-4e2b-4e79-adcb-6501fea3ff78"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>fold</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ratio</th>\n",
       "      <td>0.098452</td>\n",
       "      <td>0.095672</td>\n",
       "      <td>0.093946</td>\n",
       "      <td>0.09227</td>\n",
       "      <td>0.092032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "fold          0         1         2        3         4\n",
       "ratio  0.098452  0.095672  0.093946  0.09227  0.092032"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARgElEQVR4nO3df6zddX3H8efLVhQRBcXdmJZZFqsbuBjxihgTd2cNVLZYFtRgEKrpbKLonDPbdPujC2ii2ZRJ4o91o7MQJiKY0Uwda5AT47JWiji0MMcdirRDUAqVykSr7/1xPnVX1mvPPef0nN6e5yO5ud/v5/v5fr/v923Jq98f95CqQpI02Z4w7gIkSeNnGEiSDANJkmEgScIwkCQBS8ddQL9OOumkWrFiRV/7/vCHP+S4444bbkFHOHs++k1av2DPC3Xrrbd+v6qedbBtizYMVqxYwY4dO/rat9PpMDMzM9yCjnD2fPSbtH7BnhcqyT3zbfM2kSTJMJAkGQaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSWMS/gTyIRx/Yyy2X3TDy877kXWtGfk5J6oVXBpKkybwyeOynj3HPD+4f+XlfMvIzSlJvvDKQJBkGkqQJvU30s/0/Yd+e+8ZdhiQdMbwykCQZBpIkw0CShGEgScIwkCRhGEiS6CEMkmxK8kCSb8wZe0aSrUnuat9PbONJcnmS2SS3Jzl9zj5r2/y7kqydM/7iJF9v+1yeJMNuUpL0y/VyZfBJYPXjxt4D3FRVK4Gb2jrAq4GV7Ws98HHohgewAXgpcAaw4UCAtDlvmbPf488lSTrMDhkGVfUlYM/jhtcAm9vyZuDcOeNXVtc24IQkzwbOBrZW1Z6qegjYCqxu255WVduqqoAr5xxLkjQi/f4G8lRVHfgV3u8CU215GXDvnHm72tgvG991kPGDSrKe7hUHU1NTdDqdvopfctyxHD99Wl/7DqLfeodh3759Yz3/OExaz5PWL9jzMA38cRRVVUlqGMX0cK6NwEaA6enpmpmZ6es41191NY/s2DnEynpz3oUXjPycB3Q6Hfr9eS1Wk9bzpPUL9jxM/b5NdH+7xUP7/kAb3w2cPGfe8jb2y8aXH2RckjRC/YbBFuDAG0FrgRvmjF/U3io6E9jbbifdCJyV5MT24Pgs4Ma27QdJzmxvEV0051iSpBE55G2iJJ8CZoCTkuyi+1bQB4Brk6wD7gFe36Z/HjgHmAUeBd4MUFV7klwK3NLmXVJVBx5Kv43uG0vHAl9oX5KkETpkGFTVG+bZtOogcwu4eJ7jbAI2HWR8B/CCQ9UhSTp8/A1kSZJhIEkyDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRIDhkGSdyXZmeQbST6V5MlJTkmyPclskk8nOabNfVJbn23bV8w5znvb+DeTnD1YS5Kkheo7DJIsA/4AmK6qFwBLgPOBDwKXVdVzgYeAdW2XdcBDbfyyNo8kp7b9TgNWAx9LsqTfuiRJCzfobaKlwLFJlgJPAe4DXglc17ZvBs5ty2vaOm37qiRp49dU1WNV9S1gFjhjwLokSQuwtN8dq2p3kr8CvgP8D/AvwK3Aw1W1v03bBSxry8uAe9u++5PsBZ7ZxrfNOfTcfX5BkvXAeoCpqSk6nU5ftS857liOnz6tr30H0W+9w7Bv376xnn8cJq3nSesX7HmY+g6DJCfS/Vf9KcDDwGfo3uY5bKpqI7ARYHp6umZmZvo6zvVXXc0jO3YOsbLenHfhBSM/5wGdTod+f16L1aT1PGn9gj0P0yC3iV4FfKuqvldVPwE+C7wcOKHdNgJYDuxuy7uBkwHa9qcDD84dP8g+kqQRGCQMvgOcmeQp7d7/KuAO4GbgtW3OWuCGtrylrdO2f7Gqqo2f3942OgVYCXxlgLokSQs0yDOD7UmuA74K7Aduo3sL53PANUne18auaLtcAVyVZBbYQ/cNIqpqZ5Jr6QbJfuDiqvppv3VJkhau7zAAqKoNwIbHDd/NQd4GqqofAa+b5zjvB94/SC2SpP75G8iSJMNAkmQYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRIDhkGSE5Jcl+Q/ktyZ5GVJnpFka5K72vcT29wkuTzJbJLbk5w+5zhr2/y7kqwdtClJ0sIMemXwEeCfq+rXgRcCdwLvAW6qqpXATW0d4NXAyva1Hvg4QJJnABuAlwJnABsOBIgkaTT6DoMkTwdeAVwBUFU/rqqHgTXA5jZtM3BuW14DXFld24ATkjwbOBvYWlV7quohYCuwut+6JEkLt3SAfU8Bvgf8fZIXArcC7wSmquq+Nue7wFRbXgbcO2f/XW1svvH/J8l6ulcVTE1N0el0+ip8yXHHcvz0aX3tO4h+6x2Gffv2jfX84zBpPU9av2DPwzRIGCwFTgfeUVXbk3yE/7slBEBVVZIapMDHHW8jsBFgenq6ZmZm+jrO9VddzSM7dg6rrJ6dd+EFIz/nAZ1Oh35/XovVpPU8af2CPQ/TIM8MdgG7qmp7W7+Objjc327/0L4/0LbvBk6es//yNjbfuCRpRPoOg6r6LnBvkue3oVXAHcAW4MAbQWuBG9ryFuCi9lbRmcDedjvpRuCsJCe2B8dntTFJ0ogMcpsI4B3A1UmOAe4G3kw3YK5Nsg64B3h9m/t54BxgFni0zaWq9iS5FLilzbukqvYMWJckaQEGCoOq+howfZBNqw4yt4CL5znOJmDTILVIkvrnbyBLkgwDSZJhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkhhCGCRZkuS2JP/U1k9Jsj3JbJJPJzmmjT+prc+27SvmHOO9bfybSc4etCZJ0sIM48rgncCdc9Y/CFxWVc8FHgLWtfF1wENt/LI2jySnAucDpwGrgY8lWTKEuiRJPRooDJIsB34H+Lu2HuCVwHVtymbg3La8pq3Ttq9q89cA11TVY1X1LWAWOGOQuiRJC7N0wP3/GvgT4Pi2/kzg4ara39Z3Acva8jLgXoCq2p9kb5u/DNg255hz9/kFSdYD6wGmpqbodDp9Fb3kuGM5fvq0vvYdRL/1DsO+ffvGev5xmLSeJ61fsOdh6jsMkvwu8EBV3ZpkZnglza+qNgIbAaanp2tmpr/TXn/V1TyyY+cQK+vNeRdeMPJzHtDpdOj357VYTVrPk9Yv2PMwDXJl8HLgNUnOAZ4MPA34CHBCkqXt6mA5sLvN3w2cDOxKshR4OvDgnPED5u4jSRqBvp8ZVNV7q2p5Va2g+wD4i1V1AXAz8No2bS1wQ1ve0tZp279YVdXGz29vG50CrAS+0m9dkqSFG/SZwcH8KXBNkvcBtwFXtPErgKuSzAJ76AYIVbUzybXAHcB+4OKq+ulhqEuSNI+hhEFVdYBOW76bg7wNVFU/Al43z/7vB94/jFokSQvnbyBLkgwDSZJhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkhggDJKcnOTmJHck2ZnknW38GUm2JrmrfT+xjSfJ5Ulmk9ye5PQ5x1rb5t+VZO3gbUmSFmKQK4P9wLur6lTgTODiJKcC7wFuqqqVwE1tHeDVwMr2tR74OHTDA9gAvBQ4A9hwIEAkSaPRdxhU1X1V9dW2/AhwJ7AMWANsbtM2A+e25TXAldW1DTghybOBs4GtVbWnqh4CtgKr+61LkrRwS4dxkCQrgBcB24GpqrqvbfouMNWWlwH3ztltVxubb/xg51lP96qCqakpOp1OX/UuOe5Yjp8+ra99B9FvvcOwb9++sZ5/HCat50nrF+x5mAYOgyRPBa4H/rCqfpDk59uqqpLUoOeYc7yNwEaA6enpmpmZ6es41191NY/s2Dmssnp23oUXjPycB3Q6Hfr9eS1Wk9bzpPUL9jxMA71NlOSJdIPg6qr6bBu+v93+oX1/oI3vBk6es/vyNjbfuCRpRAZ5myjAFcCdVfXhOZu2AAfeCFoL3DBn/KL2VtGZwN52O+lG4KwkJ7YHx2e1MUnSiAxym+jlwIXA15N8rY39GfAB4Nok64B7gNe3bZ8HzgFmgUeBNwNU1Z4klwK3tHmXVNWeAeqSJC1Q32FQVV8GMs/mVQeZX8DF8xxrE7Cp31okSYPxN5AlSYaBJMkwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkMaT/uY0kTZrtn/nQeE78rBcflsMaBpLUhzu//OBYzrvi9w7Pcb1NJEkyDCRJhoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJI6gMEiyOsk3k8wmec+465GkSXJEhEGSJcBHgVcDpwJvSHLqeKuSpMlxRIQBcAYwW1V3V9WPgWuANWOuSZImRqpq3DWQ5LXA6qr6/bZ+IfDSqnr74+atB9a31ecD3+zzlCcB3+9z38XKno9+k9Yv2PNCPaeqnnWwDUv7r2f0qmojsHHQ4yTZUVXTQyhp0bDno9+k9Qv2PExHym2i3cDJc9aXtzFJ0ggcKWFwC7AyySlJjgHOB7aMuSZJmhhHxG2iqtqf5O3AjcASYFNV7TyMpxz4VtMiZM9Hv0nrF+x5aI6IB8iSpPE6Um4TSZLGyDCQJB3dYXCoj7hI8qQkn27btydZMfoqh6eHfv8oyR1Jbk9yU5LnjKPOYer1Y0ySnJekkiz61xB76TnJ69uf9c4k/zDqGoeth7/bv5rk5iS3tb/f54yjzmFJsinJA0m+Mc/2JLm8/TxuT3L6wCetqqPyi+6D6P8Cfg04Bvh34NTHzXkb8Im2fD7w6XHXfZj7/W3gKW35rYu53157bvOOB74EbAOmx133CP6cVwK3ASe29V8Zd90j6Hkj8Na2fCrw7XHXPWDPrwBOB74xz/ZzgC8AAc4Etg96zqP5yqCXj7hYA2xuy9cBq5JkhDUO0yH7raqbq+rRtrqN7u9zLGa9fozJpcAHgR+NsrjDpJee3wJ8tKoeAqiqB0Zc47D10nMBT2vLTwf+e4T1DV1VfQnY80umrAGurK5twAlJnj3IOY/mMFgG3DtnfVcbO+icqtoP7AWeOZLqhq+XfudaR/dfFovZIXtul88nV9XnRlnYYdTLn/PzgOcl+dck25KsHll1h0cvPf8F8MYku4DPA+8YTWljs9D/3g/piPg9A41WkjcC08BvjbuWwynJE4APA28acymjtpTuraIZuld/X0rym1X18FirOrzeAHyyqj6U5GXAVUleUFU/G3dhi8XRfGXQy0dc/HxOkqV0Ly8fHEl1w9fTR3okeRXw58BrquqxEdV2uByq5+OBFwCdJN+me291yyJ/iNzLn/MuYEtV/aSqvgX8J91wWKx66XkdcC1AVf0b8GS6H+h2tBr6R/gczWHQy0dcbAHWtuXXAl+s9nRmETpkv0leBPwN3SBY7PeR4RA9V9XeqjqpqlZU1Qq6z0leU1U7xlPuUPTy9/of6V4VkOQkureN7h5lkUPWS8/fAVYBJPkNumHwvZFWOVpbgIvaW0VnAnur6r5BDnjU3iaqeT7iIsklwI6q2gJcQfdycpbuw5rzx1fxYHrs9y+BpwKfac/Jv1NVrxlb0QPqseejSo893wicleQO4KfAH1fVYr3i7bXndwN/m+RddB8mv2kR/8OOJJ+iG+gntecgG4AnAlTVJ+g+FzkHmAUeBd488DkX8c9LkjQkR/NtIklSjwwDSZJhIEkyDCRJGAaSJAwDSRKGgSQJ+F95IbIdALaW9QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_folds = pd.read_csv(f'{DATA}/upsample.csv', index_col='image_id',\n",
    "                       usecols=['image_id', 'fold', 'target'], dtype={'fold': np.byte, 'target': np.byte})\n",
    "\n",
    "_ = df_folds.groupby('fold').target.hist(alpha=0.4)\n",
    "df_folds.groupby('fold').target.mean().to_frame('ratio').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3h2Zcdod4qmE"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(f'{DATA}/test.csv', index_col='image_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5i8UhuvM4qmJ",
    "outputId": "c0ea1e24-01ca-4660-af87-df919cdc884c"
   },
   "outputs": [],
   "source": [
    "ds_train, ds_val, ds_test = load_datasets(fold_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47122, 11794, 10982)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_train), len(ds_val), len(ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dqfK4rxh4qmO"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "vMgS0GCj4qmP"
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "from pytorch_lightning.metrics.classification import AUROC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.net = EfficientNet.from_pretrained(arch, advprop=True)\n",
    "        self.net._fc = nn.Linear(in_features=self.net._fc.in_features, out_features=1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            max_lr=lr,\n",
    "            epochs=max_epochs,\n",
    "            optimizer=optimizer,\n",
    "            steps_per_epoch=int(len(ds_train) / batch_size),\n",
    "            pct_start=0.1,\n",
    "            div_factor=10,\n",
    "            final_div_factor=100,\n",
    "            base_momentum=0.90,\n",
    "            max_momentum=0.95,\n",
    "        )\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def step(self, batch):\n",
    "        # return batch loss\n",
    "        x, y  = batch\n",
    "        y_hat = self(x).flatten()\n",
    "        y_smo = y.float() * (1 - label_smoothing) + 0.5 * label_smoothing\n",
    "        loss  = F.binary_cross_entropy_with_logits(y_hat, y_smo.type_as(y_hat),\n",
    "                                                   pos_weight=torch.tensor(pos_weight))\n",
    "        return loss, y, y_hat.sigmoid()\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        # hardware agnostic training\n",
    "        loss, y, y_hat = self.step(batch)\n",
    "        acc = (y_hat.round() == y).float().mean().item()\n",
    "        tensorboard_logs = {'train_loss': loss, 'acc': acc}\n",
    "        return {'loss': loss, 'acc': acc, 'log': tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        loss, y, y_hat = self.step(batch)\n",
    "        return {'val_loss': loss,\n",
    "                'y': y.detach(), 'y_hat': y_hat.detach()}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        y = torch.cat([x['y'] for x in outputs])\n",
    "        y_hat = torch.cat([x['y_hat'] for x in outputs])\n",
    "        auc = AUROC()(pred=y_hat, target=y) if y.float().mean() > 0 else 0.5 # skip sanity check\n",
    "        acc = (y_hat.round() == y).float().mean().item()\n",
    "        print(f\"Epoch {self.current_epoch} acc:{acc} auc:{auc}\")\n",
    "        tensorboard_logs = {'val_loss': avg_loss, 'val_auc': auc, 'val_acc': acc}\n",
    "        return {'avg_val_loss': avg_loss,\n",
    "                'val_auc': auc, 'val_acc': acc,\n",
    "                'log': tensorboard_logs}\n",
    "\n",
    "    def test_step(self, batch, batch_nb):\n",
    "        x, _ = batch\n",
    "        y_hat = self(x).flatten().sigmoid()\n",
    "        return {'y_hat': y_hat}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        y_hat = torch.cat([x['y_hat'] for x in outputs])\n",
    "        assert len(df_test) == len(y_hat), f\"{len(df_test)} != {len(y_hat)}\"\n",
    "        df_test['target'] = y_hat.tolist()\n",
    "        N = len(glob('submission*.csv'))\n",
    "        df_test.target.to_csv(f'submission{N}.csv')\n",
    "        return {'tta': N}\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(ds_train, batch_size=batch_size, num_workers=num_workers,\n",
    "                          drop_last=True, shuffle=True, pin_memory=False)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(ds_val, batch_size=batch_size, num_workers=num_workers,\n",
    "                          drop_last=False, shuffle=False, pin_memory=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(ds_test, batch_size=batch_size, num_workers=num_workers,\n",
    "                          drop_last=False, shuffle=False, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = sorted(list(SAVE_DIR.iterdir()), key=lambda x: int(x.stem.split('_')[0]))\n",
    "checkpoint = str(checkpoint[-1]) if len(checkpoint) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "vMgS0GCj4qmP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    }
   ],
   "source": [
    "model = Model()#.load_from_checkpoint(str(checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 185, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/content/clouderizer/melanoma/code/fastai/dataset.py\", line 19, in __getitem__\n    sample = self.transforms(image=image)\n  File \"/usr/local/lib/python3.6/dist-packages/albumentations/core/composition.py\", line 176, in __call__\n    data = t(force_apply=force_apply, **data)\nTypeError: __call__() got an unexpected keyword argument 'force_apply'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-3afeeedd2a41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot some training images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 185, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/content/clouderizer/melanoma/code/fastai/dataset.py\", line 19, in __getitem__\n    sample = self.transforms(image=image)\n  File \"/usr/local/lib/python3.6/dist-packages/albumentations/core/composition.py\", line 176, in __call__\n    data = t(force_apply=force_apply, **data)\nTypeError: __call__() got an unexpected keyword argument 'force_apply'\n"
     ]
    }
   ],
   "source": [
    "# # Plot some training images\n",
    "# import torchvision.utils as vutils\n",
    "# batch, targets = next(iter(model.train_dataloader()))\n",
    "\n",
    "# plt.figure(figsize=(16, 8))\n",
    "# plt.axis(\"off\")\n",
    "# plt.title(\"Training Images\")\n",
    "# _ = plt.imshow(vutils.make_grid(\n",
    "#     batch[:16], nrow=8, padding=2, normalize=True).cpu().numpy().transpose((1, 2, 0)))\n",
    "\n",
    "# targets[:16].reshape([2, 8]) if len(targets) >= 16 else targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/ronaldokun/melanoma\" target=\"_blank\">https://app.wandb.ai/ronaldokun/melanoma</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/ronaldokun/melanoma/runs/1puxljpf\" target=\"_blank\">https://app.wandb.ai/ronaldokun/melanoma/runs/1puxljpf</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<wandb.wandb_torch.TorchGraph at 0x7fe1e8223630>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='melanoma', tags=['lightning', 'tpu'], name='upsampled_full_data_tpu')\n",
    "wandb_logger = WandbLogger(project='melanoma', tags=['lightning', 'tpu'], name='upsampled_full_data_tpu')\n",
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# # test the same images\n",
    "# with torch.no_grad():\n",
    "#     print(model(batch[:16]).reshape([len(targets)//8,8]).sigmoid())\n",
    "# del batch; del targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1ib_IBN4qmS"
   },
   "source": [
    "# Train\n",
    "The Trainer automates the rest.\n",
    "\n",
    "Trains on 8 TPU cores, GPU or CPU - whatever is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "id": "4AEUW-iB4qmT",
    "outputId": "49468221-86ef-4e7b-b627-7d51397fad08"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: True, using: 8 TPU cores\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(filepath=OUT/\"{epoch:02d}_{val_auc:.4f}\",\n",
    "                                                   save_top_k=1, monitor='val_auc', mode='max')\n",
    "if checkpoint:\n",
    "    trainer = pl.Trainer(resume_from_checkpoint=checkpoint,\n",
    "                        default_root_dir=SAVE_DIR,\n",
    "                        tpu_cores=tpu_cores,\n",
    "                        gpus=gpus,\n",
    "                        precision=16, #if gpus else 32,\n",
    "                        max_epochs=max_epochs,\n",
    "                        checkpoint_callback=checkpoint_callback,\n",
    "                        logger=wandb_logger)\n",
    "else:\n",
    "    trainer = pl.Trainer(\n",
    "        default_root_dir=SAVE_DIR,\n",
    "        tpu_cores=tpu_cores,\n",
    "        gpus=gpus,\n",
    "        precision=16, # if gpus else 32,\n",
    "        max_epochs=max_epochs,\n",
    "        checkpoint_callback=checkpoint_callback,\n",
    "        logger=wandb_logger\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# clean up gpu in case you are debugging \n",
    "import gc\n",
    "torch.cuda.empty_cache(); gc.collect()\n",
    "torch.cuda.empty_cache(); gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "GpASvAkY4qmb",
    "outputId": "ed7fc27d-3b35-4ca9-d479-b2318582d38c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training on 8 TPU cores\n",
      "INIT TPU local core: 0, global rank: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/ronaldokun/melanoma\" target=\"_blank\">https://app.wandb.ai/ronaldokun/melanoma</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/ronaldokun/melanoma/runs/3hbsihw7\" target=\"_blank\">https://app.wandb.ai/ronaldokun/melanoma/runs/3hbsihw7</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INIT TPU local core: 5, global rank: 5\n",
      "INIT TPU local core: 3, global rank: 3\n",
      "INIT TPU local core: 6, global rank: 6\n",
      "INIT TPU local core: 1, global rank: 1\n",
      "INIT TPU local core: 2, global rank: 2\n",
      "INIT TPU local core: 4, global rank: 4\n",
      "INIT TPU local core: 7, global rank: 7\n",
      "\n",
      "  | Name | Type         | Params\n",
      "--------------------------------------\n",
      "0 | net  | EfficientNet | 28 M  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f653ffc98d54556992b51adc2bf2885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in device=TPU:0: Not found: Op type not registered 'XRTMemoryInfo' in binary running on n-b8aa50fe-w-0. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 330, in _mp_start_fn\n",
      "    _start_fn(index, pf_cfg, fn, args)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 324, in _start_fn\n",
      "    fn(gindex, *args)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/distrib_parts.py\", line 222, in tpu_train\n",
      "    self.run_pretrain_routine(model)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1196, in run_pretrain_routine\n",
      "    False)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/evaluation_loop.py\", line 272, in _evaluate\n",
      "    for batch_idx, batch in enumerate(dataloader):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/parallel_loader.py\", line 31, in __next__\n",
      "    return self.next()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/parallel_loader.py\", line 37, in next\n",
      "    xm.mark_step()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 719, in mark_step\n",
      "    wait=xu.getenv_as('XLA_SYNC_WAIT', bool, False))\n",
      "RuntimeError: Not found: Op type not registered 'XRTMemoryInfo' in binary running on n-b8aa50fe-w-0. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "Exception in device=TPU:6: Not found: Op type not registered 'XRTMemoryInfo' in binary running on n-b8aa50fe-w-0. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "Exception in device=TPU:7: Not found: Op type not registered 'XRTMemoryInfo' in binary running on n-b8aa50fe-w-0. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 330, in _mp_start_fn\n",
      "    _start_fn(index, pf_cfg, fn, args)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 324, in _start_fn\n",
      "    fn(gindex, *args)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/distrib_parts.py\", line 222, in tpu_train\n",
      "    self.run_pretrain_routine(model)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1196, in run_pretrain_routine\n",
      "    False)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/evaluation_loop.py\", line 272, in _evaluate\n",
      "    for batch_idx, batch in enumerate(dataloader):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/parallel_loader.py\", line 31, in __next__\n",
      "    return self.next()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/parallel_loader.py\", line 37, in next\n",
      "    xm.mark_step()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 719, in mark_step\n",
      "    wait=xu.getenv_as('XLA_SYNC_WAIT', bool, False))\n",
      "RuntimeError: Not found: Op type not registered 'XRTMemoryInfo' in binary running on n-b8aa50fe-w-0. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "process 0 terminated with exit code 17",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-45d4afebefac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders)\u001b[0m\n\u001b[1;32m   1019\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                 \u001b[0mxmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_cores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0;31m# load weights if not interrupted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mdaemon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         start_method=start_method)\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 raise Exception(\n\u001b[1;32m    112\u001b[0m                     \u001b[0;34m\"process %d terminated with exit code %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;34m(\u001b[0m\u001b[0merror_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                 )\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: process 0 terminated with exit code 17"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
