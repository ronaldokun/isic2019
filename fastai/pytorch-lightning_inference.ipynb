{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkQEDQA44qlC"
   },
   "source": [
    "# Melanoma classification with PyTorch Lightning\n",
    "\n",
    "Using EfficientNet on PyTorch Lightning, with its amazing hardware agnostic and mixed precision implementation.\n",
    "\n",
    "This is still work in progress, so please bear with me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ftZsAlKR4qlF"
   },
   "outputs": [],
   "source": [
    "fold_number = 0\n",
    "tta   = 20\n",
    "\n",
    "batch_size = {\n",
    "    'tpu': 10, # x8\n",
    "    'gpu': 22, # 10 without AMP\n",
    "    'cpu': 4,\n",
    "}\n",
    "\n",
    "arch = 'efficientnet-b5'\n",
    "resolution = 456  # orignal res for B5\n",
    "input_res  = 512\n",
    "\n",
    "lr = 8e-6   # * batch_size\n",
    "weight_decay = 2e-5\n",
    "pos_weight   = 3.2\n",
    "label_smoothing = 0.03\n",
    "\n",
    "max_epochs = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = batch_size['gpu']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oa7QSur04qlR"
   },
   "source": [
    "# Install modules\n",
    "\n",
    "Update PyTorch to enable its native support to Mixed Precision or XLA for TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "id": "_lmyKFye4qlT",
    "outputId": "a008eca4-4ec3-4ac7-a1a8-7f72cfa3c337"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/nightly/cu101/torch_nightly.html\n",
      "Requirement already satisfied: torch==1.7.0.dev20200701+cu101 in /usr/local/lib/python3.6/dist-packages (1.7.0.dev20200701+cu101)\n",
      "Requirement already satisfied: torchvision==0.8.0.dev20200701+cu101 in /usr/local/lib/python3.6/dist-packages (0.8.0.dev20200701+cu101)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0.dev20200701+cu101) (0.18.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0.dev20200701+cu101) (1.18.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.8.0.dev20200701+cu101) (7.0.0)\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRdfuFiR4qlf"
   },
   "source": [
    "# Hardware lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true,
    "id": "t9FS-xGM4qlh",
    "outputId": "5802bc07-8b6e-4254-ac49-2139d11911f8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "num_workers = os.cpu_count()\n",
    "gpus = 1 if torch.cuda.is_available() else None\n",
    "\n",
    "try:\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    tpu_cores = 8 #xm.xrt_world_size()\n",
    "except:\n",
    "    tpu_cores = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true,
    "id": "t9FS-xGM4qlh",
    "outputId": "5802bc07-8b6e-4254-ac49-2139d11911f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 22,\n",
       " 'gpus': 1,\n",
       " 'lr': 0.000176,\n",
       " 'num_workers': 4,\n",
       " 'tpu_cores': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if isinstance(batch_size, dict):\n",
    "    if tpu_cores:\n",
    "        batch_size = batch_size['tpu']\n",
    "        lr *= tpu_cores\n",
    "        num_workers = 1\n",
    "    elif gpus:\n",
    "        batch_size = batch_size['gpu']\n",
    "        # support for free Colab GPU's\n",
    "        if 'K80' in torch.cuda.get_device_name():\n",
    "            batch_size = batch_size//3\n",
    "        elif 'T4' in torch.cuda.get_device_name():\n",
    "            batch_size = int(batch_size * 0.66)\n",
    "    else:\n",
    "        batch_size = batch_size['cpu']\n",
    "\n",
    "lr *= batch_size\n",
    "\n",
    "dict(\n",
    "    num_workers=num_workers,\n",
    "    tpu_cores=tpu_cores,\n",
    "    gpus=gpus,\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fa--zHZ64qln"
   },
   "source": [
    "# Automatic Mixed Precision\n",
    "\n",
    "NVIDIA Apex is required only prior to PyTorch 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "id": "2jNntNJb4qln"
   },
   "outputs": [],
   "source": [
    "# check for torch's native mixed precision support (pt1.6+)\n",
    "if gpus and not hasattr(torch.cuda, \"amp\"):\n",
    "    try:\n",
    "        from apex import amp\n",
    "    except:\n",
    "        !git clone https://github.com/NVIDIA/apex  nv_apex\n",
    "        !pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./nv_apex\n",
    "        from apex import amp\n",
    "    # with PyTorch Lightning all you need to do now is set precision=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaoinaAu4qlu"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "id": "UFXXIDJt4qlv",
    "outputId": "b5e99e4c-016c-440c-e2f4-c3ed45ba50eb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'1.7.0.dev20200701+cu101'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "from skimage import io\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from glob import glob\n",
    "import sklearn\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "from dataset import load_datasets\n",
    "from utils import get_train_transforms, get_val_transforms, get_tta_transforms\n",
    "from data import *\n",
    "from pathlib import Path\n",
    "from fastprogress import progress_bar as tqdm\n",
    "SAVE_DIR = OUT / f'pl/fold_{fold_number}'\n",
    "SAVE_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train, ds_val, ds_test = load_datasets(fold_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dqfK4rxh4qmO"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "vMgS0GCj4qmP"
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "from pytorch_lightning.metrics.classification import AUROC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.net = EfficientNet.from_pretrained(arch, advprop=True)\n",
    "        self.net._fc = nn.Linear(in_features=self.net._fc.in_features, out_features=1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            max_lr=lr,\n",
    "            epochs=max_epochs,\n",
    "            optimizer=optimizer,\n",
    "            steps_per_epoch=int(len(ds_train) / batch_size),\n",
    "            pct_start=0.1,\n",
    "            div_factor=10,\n",
    "            final_div_factor=100,\n",
    "            base_momentum=0.90,\n",
    "            max_momentum=0.95,\n",
    "        )\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def step(self, batch):\n",
    "        # return batch loss\n",
    "        x, y  = batch\n",
    "        y_hat = self(x).flatten()\n",
    "        y_smo = y.float() * (1 - label_smoothing) + 0.5 * label_smoothing\n",
    "        loss  = F.binary_cross_entropy_with_logits(y_hat, y_smo.type_as(y_hat),\n",
    "                                                   pos_weight=torch.tensor(pos_weight))\n",
    "        return loss, y, y_hat.sigmoid()\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        # hardware agnostic training\n",
    "        loss, y, y_hat = self.step(batch)\n",
    "        acc = (y_hat.round() == y).float().mean().item()\n",
    "        tensorboard_logs = {'train_loss': loss, 'acc': acc}\n",
    "        return {'loss': loss, 'acc': acc, 'log': tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        loss, y, y_hat = self.step(batch)\n",
    "        return {'val_loss': loss,\n",
    "                'y': y.detach(), 'y_hat': y_hat.detach()}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        y = torch.cat([x['y'] for x in outputs])\n",
    "        y_hat = torch.cat([x['y_hat'] for x in outputs])\n",
    "        auc = AUROC()(pred=y_hat, target=y) if y.float().mean() > 0 else 0.5 # skip sanity check\n",
    "        acc = (y_hat.round() == y).float().mean().item()\n",
    "        print(f\"Epoch {self.current_epoch} acc:{acc} auc:{auc}\")\n",
    "        tensorboard_logs = {'val_loss': avg_loss, 'val_auc': auc, 'val_acc': acc}\n",
    "        return {'avg_val_loss': avg_loss,\n",
    "                'val_auc': auc, 'val_acc': acc,\n",
    "                'log': tensorboard_logs}\n",
    "\n",
    "    def test_step(self, batch, batch_nb):\n",
    "        x, _ = batch\n",
    "        y_hat = self(x).flatten().sigmoid()\n",
    "        return {'y_hat': y_hat}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        y_hat = torch.cat([x['y_hat'] for x in outputs])\n",
    "        assert len(df_test) == len(y_hat), f\"{len(df_test)} != {len(y_hat)}\"\n",
    "        df_test['target'] = y_hat.tolist()\n",
    "        N = len(glob('submission*.csv'))\n",
    "        df_test.target.to_csv(f'submission{N}.csv')\n",
    "        return {'tta': N}\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(ds_train, batch_size=batch_size, num_workers=num_workers,\n",
    "                          drop_last=True, shuffle=True, pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(ds_val, batch_size=batch_size, num_workers=num_workers,\n",
    "                          drop_last=False, shuffle=False, pin_memory=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(ds_test, batch_size=batch_size, num_workers=num_workers,\n",
    "                          drop_last=False, shuffle=False, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = sorted(list(SAVE_DIR.iterdir()), key=lambda x: float(x.stem.split('=')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "vMgS0GCj4qmP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    }
   ],
   "source": [
    "model = Model()#.load_from_checkpoint(str(checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "id": "4AEUW-iB4qmT",
    "outputId": "49468221-86ef-4e7b-b627-7d51397fad08"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'checkpoint_callback' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-15a04e7febe0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mnum_sanity_val_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;31m#logger=wandb_logger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                         )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'checkpoint_callback' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(resume_from_checkpoint=str(checkpoint),\n",
    "                        default_root_dir=str(SAVE_DIR),\n",
    "                        tpu_cores=tpu_cores,\n",
    "                        gpus=gpus,\n",
    "                        precision=16 if gpus else 32,\n",
    "                        max_epochs=max_epochs)                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4WrS30T4qmj"
   },
   "source": [
    "# Submission\n",
    "Infer on test set using a simple random TTA (test-time augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adaa2b1cac3244b58d444e8d0a6edaa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "TEST RESULTS\n",
      "{'tta': 0}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe0dd3048d84d93acc53e36c5de89bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "for _ in range(tta):\n",
    "     trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "2HEluAlSiRsr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    0.0\n",
       "mean     NaN\n",
       "std      NaN\n",
       "min      NaN\n",
       "25%      NaN\n",
       "50%      NaN\n",
       "75%      NaN\n",
       "max      NaN\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# merge TTA\n",
    "submission = df_test.copy() \n",
    "submission['target'] = 0.0\n",
    "for sub in glob(f'{SAVE_DIR}/submission*.csv'):\n",
    "    targets += pd.read_csv(sub, index_col='image_name').target\n",
    "    if targets.isna().any():\n",
    "        Path(sub).unlink()\n",
    "        continue\n",
    "    submission['target'] += targets.values\n",
    "\n",
    "# min-max norm\n",
    "submission['target'] -= submission.target.min()\n",
    "submission['target'] /= submission.target.max()\n",
    "\n",
    "submission.hist(bins=100, log=True, alpha=0.6)\n",
    "submission.target.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.reset_index()[['image_name', 'target']].to_csv(f'{SAVE_DIR}/submission_fold{fold_number}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_sub = [pd.read_csv(path, index_col='image_name') for path in SAVE_DIR.iterdir() if '_fold' in path.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in folds_sub:\n",
    "    # incremental blend with equal weights for all folds\n",
    "    submission.target += fold.target\n",
    "    submission.target /= len(folds_sub)\n",
    "\n",
    "submission.to_csv(SAVE_DIR.parent / 'submission.csv', index=False)\n",
    "\n",
    "submission.hist(bins=100, log=True, alpha=0.6)\n",
    "submission.target.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c siim-isic-melanoma-classification -f {SAVE_DIR.parent}/submission.csv -m \"Pytorch Lightning Upsampled Full Data\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
