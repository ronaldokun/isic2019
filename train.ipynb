{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "(45780,)\n",
      "(45824,)\n",
      "(45912,)\n",
      "(45662,)\n",
      "(45718,)\n",
      "Val\n",
      "(11444,)\n",
      "(11400,)\n",
      "(11312,)\n",
      "(11562,)\n",
      "(11506,)\n",
      "Train\n",
      "(45780,)\n",
      "(45824,)\n",
      "(45912,)\n",
      "(45662,)\n",
      "(45718,)\n",
      "Val\n",
      "(11444,)\n",
      "(11400,)\n",
      "(11312,)\n",
      "(11562,)\n",
      "(11506,)\n",
      "Train\n",
      "(45780,)\n",
      "(45824,)\n",
      "(45912,)\n",
      "(45662,)\n",
      "(45718,)\n",
      "Val\n",
      "(11444,)\n",
      "(11400,)\n",
      "(11312,)\n",
      "(11562,)\n",
      "(11506,)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models as tv_models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import confusion_matrix, auc, roc_curve, f1_score, classification_report\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "import threading\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from glob import glob\n",
    "import re\n",
    "import gc\n",
    "import importlib\n",
    "import time\n",
    "import sklearn.preprocessing\n",
    "import utils\n",
    "from sklearn.utils import class_weight\n",
    "import psutil\n",
    "import models\n",
    "from tqdm import tqdm\n",
    "# from fastprogress import progress_bar as tqdm\n",
    "# from fastprogress import master_bar as mb\n",
    "from cfgs.test_effb0_ss import params\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getErrClassification_mgpu(mdlParams, indices, modelVars, exclude_class=None):\n",
    "    \"\"\"Helper function to return the error of a set\n",
    "    Args:\n",
    "      mdlParams: dictionary, configuration file\n",
    "      indices: string, either \"trainInd\", \"valInd\" or \"testInd\"\n",
    "    Returns:\n",
    "      loss: float, avg loss\n",
    "      acc: float, accuracy\n",
    "      sensitivity: float, sensitivity\n",
    "      spec: float, specificity\n",
    "      conf: float matrix, confusion matrix\n",
    "    \"\"\"\n",
    "    # Set up sizes\n",
    "    if indices == 'trainInd':\n",
    "        numBatches = int(math.floor(len(mdlParams[indices])/mdlParams['batchSize']/mdlParams['numGPUs']))\n",
    "    else:\n",
    "        numBatches = int(math.ceil(len(mdlParams[indices])/mdlParams['batchSize']/mdlParams['numGPUs']))\n",
    "    # Consider multi-crop case\n",
    "    if mdlParams.get('eval_flipping',0) > 1 and mdlParams.get('multiCropEval',0) > 0:\n",
    "        loss_all = np.zeros([numBatches])\n",
    "        predictions = np.zeros([len(mdlParams[indices]),mdlParams['numClasses']])\n",
    "        targets = np.zeros([len(mdlParams[indices]),mdlParams['numClasses']])        \n",
    "        loss_mc = np.zeros([len(mdlParams[indices])*mdlParams['eval_flipping']])\n",
    "        predictions_mc = np.zeros([len(mdlParams[indices]),mdlParams['numClasses'],mdlParams['multiCropEval'],mdlParams['eval_flipping']])\n",
    "        targets_mc = np.zeros([len(mdlParams[indices]),mdlParams['numClasses'],mdlParams['multiCropEval'],mdlParams['eval_flipping']])  \n",
    "        # Very suboptimal method\n",
    "        ind = -1\n",
    "        for i, (inputs, labels, inds, flip_ind) in enumerate(modelVars['dataloader_'+indices]):\n",
    "            if flip_ind[0] != np.mean(np.array(flip_ind)):\n",
    "                print(\"Problem with flipping\",flip_ind)\n",
    "            if flip_ind[0] == 0:\n",
    "                ind += 1\n",
    "            # Get data\n",
    "            if mdlParams.get('meta_features',None) is not None: \n",
    "                inputs[0] = inputs[0].cuda()\n",
    "                inputs[1] = inputs[1].cuda()\n",
    "            else:            \n",
    "                inputs = inputs.to(modelVars['device'])\n",
    "            labels = labels.to(modelVars['device'])       \n",
    "            # Not sure if thats necessary\n",
    "            modelVars['optimizer'].zero_grad()    \n",
    "            with torch.set_grad_enabled(False):\n",
    "                # Get outputs\n",
    "                if mdlParams.get('aux_classifier',False):\n",
    "                    outputs, outputs_aux = modelVars['model'](inputs)\n",
    "                    if mdlParams['eval_aux_classifier']:\n",
    "                        outputs = outputs_aux\n",
    "                else:\n",
    "                    outputs = modelVars['model'](inputs)\n",
    "                preds = modelVars['softmax'](outputs)      \n",
    "                # Loss\n",
    "                loss = modelVars['criterion'](outputs, labels)           \n",
    "            # Write into proper arrays\n",
    "            loss_mc[ind] = np.mean(loss.cpu().numpy())\n",
    "            predictions_mc[ind,:,:,flip_ind[0]] = np.transpose(preds.cpu().numpy())\n",
    "            tar_not_one_hot = labels.data.cpu().numpy()\n",
    "            tar = np.zeros((tar_not_one_hot.shape[0], mdlParams['numClasses']))\n",
    "            tar[np.arange(tar_not_one_hot.shape[0]),tar_not_one_hot] = 1\n",
    "            targets_mc[ind,:,:,flip_ind[0]] = np.transpose(tar)\n",
    "        # Targets stay the same\n",
    "        targets = targets_mc[:,:,0,0]\n",
    "        # reshape preds\n",
    "        predictions_mc = np.reshape(predictions_mc,[predictions_mc.shape[0],predictions_mc.shape[1],mdlParams['multiCropEval']*mdlParams['eval_flipping']])\n",
    "        if mdlParams['voting_scheme'] == 'vote':\n",
    "            # Vote for correct prediction\n",
    "            print(\"Pred Shape\",predictions_mc.shape)\n",
    "            predictions_mc = np.argmax(predictions_mc,1)    \n",
    "            print(\"Pred Shape\",predictions_mc.shape) \n",
    "            for j in range(predictions_mc.shape[0]):\n",
    "                predictions[j,:] = np.bincount(predictions_mc[j,:],minlength=mdlParams['numClasses'])   \n",
    "            print(\"Pred Shape\",predictions.shape) \n",
    "        elif mdlParams['voting_scheme'] == 'average':\n",
    "            predictions = np.mean(predictions_mc,2)        \n",
    "    elif mdlParams.get('multiCropEval',0) > 0:\n",
    "        loss_all = np.zeros([numBatches])\n",
    "        predictions = np.zeros([len(mdlParams[indices]),mdlParams['numClasses']])\n",
    "        targets = np.zeros([len(mdlParams[indices]),mdlParams['numClasses']])        \n",
    "        loss_mc = np.zeros([len(mdlParams[indices])])\n",
    "        predictions_mc = np.zeros([len(mdlParams[indices]),mdlParams['numClasses'],mdlParams['multiCropEval']])\n",
    "        targets_mc = np.zeros([len(mdlParams[indices]),mdlParams['numClasses'],mdlParams['multiCropEval']])\n",
    "        for i, (inputs, labels, inds) in tqdm(enumerate(modelVars['dataloader_'+indices]), total=len(mdlParams[indices])):\n",
    "            # Get data\n",
    "            if mdlParams.get('meta_features',None) is not None: \n",
    "                inputs[0] = inputs[0].cuda()\n",
    "                inputs[1] = inputs[1].cuda()\n",
    "            else:            \n",
    "                inputs = inputs.to(modelVars['device'])\n",
    "            labels = labels.to(modelVars['device'])       \n",
    "            # Not sure if thats necessary\n",
    "            modelVars['optimizer'].zero_grad()    \n",
    "            with torch.set_grad_enabled(False):\n",
    "                # Get outputs\n",
    "                if mdlParams.get('aux_classifier',False):\n",
    "                    outputs, outputs_aux = modelVars['model'](inputs)\n",
    "                    if mdlParams['eval_aux_classifier']:\n",
    "                        outputs = outputs_aux\n",
    "                else:\n",
    "                    outputs = modelVars['model'](inputs)\n",
    "                preds = modelVars['softmax'](outputs)      \n",
    "                # Loss\n",
    "                loss = modelVars['criterion'](outputs, labels)           \n",
    "            # Write into proper arrays\n",
    "            loss_mc[i] = np.mean(loss.cpu().numpy())\n",
    "            #print(f'predictions_mc shape: {predictions_mc[i].shape}')\n",
    "            predictions_mc[i,:,:] = np.transpose(preds.cpu().numpy()) #[:,mdlParams['multiCropEval']-1]\n",
    "            tar_not_one_hot = labels.data.cpu().numpy()\n",
    "            tar = np.zeros((tar_not_one_hot.shape[0], mdlParams['numClasses']))\n",
    "            tar[np.arange(tar_not_one_hot.shape[0]),tar_not_one_hot] = 1\n",
    "            targets_mc[i,:,:] = np.transpose(tar)\n",
    "        # Targets stay the same\n",
    "        targets = targets_mc[:,:,0]\n",
    "        if mdlParams['voting_scheme'] == 'vote':\n",
    "            # Vote for correct prediction\n",
    "            print(\"Pred Shape\",predictions_mc.shape)\n",
    "            predictions_mc = np.argmax(predictions_mc,1)    \n",
    "            print(\"Pred Shape\",predictions_mc.shape) \n",
    "            for j in range(predictions_mc.shape[0]):\n",
    "                predictions[j,:] = np.bincount(predictions_mc[j,:],minlength=mdlParams['numClasses'])   \n",
    "            print(\"Pred Shape\",predictions.shape) \n",
    "        elif mdlParams['voting_scheme'] == 'average':\n",
    "            predictions = np.mean(predictions_mc,2)\n",
    "    else:    \n",
    "        if mdlParams.get('model_type_cnn') is not None and mdlParams['numRandValSeq'] > 0:\n",
    "            loss_all = np.zeros([numBatches])\n",
    "            predictions = np.zeros([len(mdlParams[indices]),mdlParams['numClasses']])\n",
    "            targets = np.zeros([len(mdlParams[indices]),mdlParams['numClasses']])        \n",
    "            loss_mc = np.zeros([len(mdlParams[indices])])\n",
    "            predictions_mc = np.zeros([len(mdlParams[indices]),mdlParams['numClasses'],mdlParams['numRandValSeq']])\n",
    "            targets_mc = np.zeros([len(mdlParams[indices]),mdlParams['numClasses'],mdlParams['numRandValSeq']])   \n",
    "            for i, (inputs, labels, inds) in enumerate(modelVars['dataloader_'+indices]):\n",
    "                # Get data\n",
    "                if mdlParams.get('meta_features',None) is not None: \n",
    "                    inputs[0] = inputs[0].cuda()\n",
    "                    inputs[1] = inputs[1].cuda()\n",
    "                else:            \n",
    "                    inputs = inputs.to(modelVars['device'])\n",
    "                labels = labels.to(modelVars['device'])       \n",
    "                # Not sure if thats necessary\n",
    "                modelVars['optimizer'].zero_grad()    \n",
    "                with torch.set_grad_enabled(False):\n",
    "                    # Get outputs\n",
    "                    if mdlParams.get('aux_classifier',False):\n",
    "                        outputs, outputs_aux = modelVars['model'](inputs)\n",
    "                        if mdlParams['eval_aux_classifier']:\n",
    "                            outputs = outputs_aux\n",
    "                    else:\n",
    "                        outputs = modelVars['model'](inputs)\n",
    "                    preds = modelVars['softmax'](outputs)      \n",
    "                    # Loss\n",
    "                    loss = modelVars['criterion'](outputs, labels)           \n",
    "                # Write into proper arrays\n",
    "                loss_mc[i] = np.mean(loss.cpu().numpy())\n",
    "                predictions_mc[i,:,:] = np.transpose(preds)\n",
    "                tar_not_one_hot = labels.data.cpu().numpy()\n",
    "                tar = np.zeros((tar_not_one_hot.shape[0], mdlParams['numClasses']))\n",
    "                tar[np.arange(tar_not_one_hot.shape[0]),tar_not_one_hot] = 1\n",
    "                targets_mc[i,:,:] = np.transpose(tar)\n",
    "            # Targets stay the same\n",
    "            targets = targets_mc[:,:,0]\n",
    "            if mdlParams['voting_scheme'] == 'vote':\n",
    "                # Vote for correct prediction\n",
    "                print(\"Pred Shape\",predictions_mc.shape)\n",
    "                predictions_mc = np.argmax(predictions_mc,1)    \n",
    "                print(\"Pred Shape\",predictions_mc.shape) \n",
    "                for j in range(predictions_mc.shape[0]):\n",
    "                    predictions[j,:] = np.bincount(predictions_mc[j,:],minlength=mdlParams['numClasses'])   \n",
    "                print(\"Pred Shape\",predictions.shape) \n",
    "            elif mdlParams['voting_scheme'] == 'average':\n",
    "                predictions = np.mean(predictions_mc,2)\n",
    "        else:\n",
    "            for i, (inputs, labels, indices) in enumerate(modelVars['dataloader_'+indices]):\n",
    "                # Get data\n",
    "                if mdlParams.get('meta_features',None) is not None: \n",
    "                    inputs[0] = inputs[0].cuda()\n",
    "                    inputs[1] = inputs[1].cuda()\n",
    "                else:            \n",
    "                    inputs = inputs.to(modelVars['device'])\n",
    "                labels = labels.to(modelVars['device'])       \n",
    "                # Not sure if thats necessary\n",
    "                modelVars['optimizer'].zero_grad()    \n",
    "                with torch.set_grad_enabled(False):\n",
    "                    # Get outputs\n",
    "                    if mdlParams.get('aux_classifier',False):\n",
    "                        outputs, outputs_aux = modelVars['model'](inputs)\n",
    "                        if mdlParams['eval_aux_classifier']:\n",
    "                            outputs = outputs_aux\n",
    "                    else:\n",
    "                        outputs = modelVars['model'](inputs)\n",
    "                    #print(\"in\",inputs.shape,\"out\",outputs.shape)\n",
    "                    preds = modelVars['softmax'](outputs)      \n",
    "                    # Loss\n",
    "                    loss = modelVars['criterion'](outputs, labels)     \n",
    "                # Write into proper arrays                \n",
    "                if i==0:\n",
    "                    loss_all = np.array([loss.cpu().numpy()])\n",
    "                    predictions = preds.cpu().numpy()\n",
    "                    tar_not_one_hot = labels.data.cpu().numpy()\n",
    "                    tar = np.zeros((tar_not_one_hot.shape[0], mdlParams['numClasses']))\n",
    "                    tar[np.arange(tar_not_one_hot.shape[0]),tar_not_one_hot] = 1   \n",
    "                    targets = tar    \n",
    "                    #print(\"Loss\",loss_all)         \n",
    "                else:                 \n",
    "                    loss_all = np.concatenate((loss_all,np.array([loss.cpu().numpy()])),0)\n",
    "                    predictions = np.concatenate((predictions,preds.cpu().numpy()),0)\n",
    "                    tar_not_one_hot = labels.data.cpu().numpy()\n",
    "                    tar = np.zeros((tar_not_one_hot.shape[0], mdlParams['numClasses']))\n",
    "                    tar[np.arange(tar_not_one_hot.shape[0]),tar_not_one_hot] = 1                   \n",
    "                    targets = np.concatenate((targets,tar),0)\n",
    "                    #allInds[(i*len(mdlParams['numGPUs'])+k)*bSize:(i*len(mdlParams['numGPUs'])+k+1)*bSize] = res_tuple[3][k]\n",
    "            predictions_mc = predictions\n",
    "    #print(\"Check Inds\",np.setdiff1d(allInds,mdlParams[indices]))\n",
    "    # Calculate metrics\n",
    "    if exclude_class is not None:\n",
    "        predictions = np.concatenate((predictions[:,:exclude_class],predictions[:,exclude_class+1:]),1)\n",
    "        targets = np.concatenate((targets[:,:exclude_class],targets[:,exclude_class+1:]),1)    \n",
    "        num_classes = mdlParams['numClasses']-1\n",
    "    elif mdlParams['numClasses'] == 9 and mdlParams.get('no_c9_eval',False):\n",
    "        predictions = predictions[:,:mdlParams['numClasses']-1]\n",
    "        targets = targets[:,:mdlParams['numClasses']-1]\n",
    "        num_classes = mdlParams['numClasses']-1\n",
    "    else:\n",
    "        num_classes = mdlParams['numClasses']\n",
    "    # Accuarcy\n",
    "    acc = np.mean(np.equal(np.argmax(predictions,1),np.argmax(targets,1)))\n",
    "    # Confusion matrix\n",
    "    conf = confusion_matrix(np.argmax(targets,1),np.argmax(predictions,1))\n",
    "    if conf.shape[0] < num_classes:\n",
    "        conf = np.ones([num_classes,num_classes])\n",
    "    # Class weighted accuracy\n",
    "    wacc = conf.diagonal()/conf.sum(axis=1)    \n",
    "    # Sensitivity / Specificity\n",
    "    sensitivity = np.zeros([num_classes])\n",
    "    specificity = np.zeros([num_classes])\n",
    "    if num_classes > 2:\n",
    "        for k in range(num_classes):\n",
    "                sensitivity[k] = conf[k,k]/(np.sum(conf[k,:]))\n",
    "                true_negative = np.delete(conf,[k],0)\n",
    "                true_negative = np.delete(true_negative,[k],1)\n",
    "                true_negative = np.sum(true_negative)\n",
    "                false_positive = np.delete(conf,[k],0)\n",
    "                false_positive = np.sum(false_positive[:,k])\n",
    "                specificity[k] = true_negative/(true_negative+false_positive)\n",
    "                # F1 score\n",
    "                f1 = f1_score(np.argmax(predictions,1),np.argmax(targets,1),average='weighted')                \n",
    "    else:\n",
    "        tn, fp, fn, tp = confusion_matrix(np.argmax(targets,1),np.argmax(predictions,1)).ravel()\n",
    "        sensitivity = tp/(tp+fn)\n",
    "        specificity = tn/(tn+fp)\n",
    "        # F1 score\n",
    "        f1 = f1_score(np.argmax(predictions,1),np.argmax(targets,1))\n",
    "    # AUC\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    roc_auc = np.zeros([num_classes])\n",
    "    if num_classes > 9:\n",
    "        print(predictions)\n",
    "    for i in range(num_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(targets[:, i], predictions[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    return np.mean(loss_all), acc, sensitivity, specificity, conf, f1, roc_auc, wacc, predictions, targets, predictions_mc \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT = 'test_effb0_ss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path name from filename\n",
    "params['save_dir_base'] = params['save_dir'] / OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['save_dir_base'].mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set during training.\n"
     ]
    }
   ],
   "source": [
    "# Check if there is a validation set, if not, evaluate train error instead\n",
    "if 'valIndCV' in params or 'valInd' in params:\n",
    "    eval_set = 'valInd'\n",
    "    print(\"Evaluating on validation set during training.\")\n",
    "else:\n",
    "    eval_set = 'trainInd'\n",
    "    print(\"No validation set, evaluating on training set during training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there were previous ones that have alreary bin learned\n",
    "prevFile = Path(params['save_dir_base'] / 'CV.pkl')\n",
    "#print(prevFile)\n",
    "if prevFile.exists():\n",
    "    print(\"Part of CV already done\")\n",
    "    with open(params['save_dir_base'] / 'CV.pkl', 'rb') as f:\n",
    "        allData = pickle.load(f)\n",
    "else:\n",
    "    allData = {}\n",
    "    allData['f1Best'] = {}\n",
    "    allData['sensBest'] = {}\n",
    "    allData['specBest'] = {}\n",
    "    allData['accBest'] = {}\n",
    "    allData['waccBest'] = {}\n",
    "    allData['aucBest'] = {}\n",
    "    allData['convergeTime'] = {}\n",
    "    allData['bestPred'] = {}\n",
    "    allData['targets'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cv(cv):\n",
    "    # Check if this fold was already trained\n",
    "    already_trained, load_old = False, False\n",
    "    # Def current CV set\n",
    "    params['trainInd'] = params['trainIndCV'][cv]\n",
    "    params['valInd'] = params['valIndCV'][cv]\n",
    "    # Def current path for saving stuff\n",
    "    if 'valIndCV' in params:\n",
    "        params['save_dir'] = params['save_dir_base'] / f'CVSet{cv}'\n",
    "        if params['save_dir_base'].is_dir():\n",
    "            if params['save_dir'].is_dir():\n",
    "                all_max_iter = []\n",
    "                for name in params['save_dir'].iterdir():\n",
    "                    load_old = True\n",
    "                    int_list = [int(s) for s in re.findall(r'\\d+',str(name))]\n",
    "                    if len(int_list) > 0:\n",
    "                        all_max_iter.append(int_list[-1])\n",
    "                all_max_iter = np.array(all_max_iter)\n",
    "                if len(all_max_iter) > 0 and np.max(all_max_iter) >= params['training_steps']:\n",
    "                    print(\"Fold %d already fully trained with %d iterations\"%(cv,np.max(all_max_iter)))\n",
    "                    already_trained = True\n",
    "    else:\n",
    "        params['save_dir'] = params['save_dir_base']\n",
    "        \n",
    "    return already_trained, load_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_classes():\n",
    "    # balance classes\n",
    "    if params['balance_classes'] in (1,2, 7, 11):\n",
    "        class_weights = class_weight.compute_class_weight('balanced',np.unique(np.argmax(params['labels_array'][params['trainInd'],:],1)),np.argmax(params['labels_array'][params['trainInd'],:],1)) \n",
    "        class_weights = class_weights*params['extra_fac']\n",
    "    elif params['balance_classes'] in (3,4):\n",
    "        # Split training set by classes\n",
    "        not_one_hot = np.argmax(params['labels_array'],1)\n",
    "        params['class_indices'] = []\n",
    "        for i in range(params['numClasses']):\n",
    "            params['class_indices'].append(np.where(not_one_hot==i)[0])\n",
    "            # Kick out non-trainind indices\n",
    "            params['class_indices'][i] = np.setdiff1d(params['class_indices'][i],params['valInd'])\n",
    "    elif params['balance_classes'] in (5,6,13):\n",
    "        # Other class balancing loss\n",
    "        class_weights = 1.0/np.mean(params['labels_array'][params['trainInd'],:],axis=0)        \n",
    "    elif params['balance_classes'] == 9:\n",
    "        # Only use official indicies for calculation\n",
    "        print(\"Balance 9\")\n",
    "        indices_ham = params['trainInd'][params['trainInd'] < 25331]\n",
    "        if params['numClasses'] == 9:\n",
    "            class_weights_ = 1.0/np.mean(params['labels_array'][indices_ham,:8],axis=0)\n",
    "            class_weights = np.zeros([params['numClasses']])\n",
    "            class_weights[:8] = class_weights_\n",
    "            class_weights[-1] = np.max(class_weights_)\n",
    "        else:\n",
    "            class_weights = 1.0/np.mean(params['labels_array'][indices_ham,:],axis=0)\n",
    "            \n",
    "    if isinstance(params['extra_fac'], float):\n",
    "        class_weights = np.power(class_weights,params['extra_fac'])\n",
    "    else:\n",
    "        class_weights = class_weights*params['extra_fac']\n",
    "        \n",
    "    params['class_weights'] = class_weights\n",
    "\n",
    "    print(\"Current class weights with extra\",class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders():\n",
    "    # Set up dataloaders\n",
    "    num_workers = psutil.cpu_count(logical=False)\n",
    "    # For train\n",
    "    dataset_train = utils.ISICDataset(params, 'trainInd')\n",
    "    # For val\n",
    "    dataset_val = utils.ISICDataset(params, 'valInd')\n",
    "    params['len_train'] = len(dataset_train)\n",
    "    params['len_val'] = len(dataset_val)\n",
    "    if params['multiCropEval'] > 0:\n",
    "        modelVars['dataloader_valInd'] = DataLoader(dataset_val, batch_size=params['multiCropEval'], shuffle=False, num_workers=num_workers, pin_memory=True)  \n",
    "    else:\n",
    "        modelVars['dataloader_valInd'] = DataLoader(dataset_val, batch_size=params['batchSize'], shuffle=False, num_workers=num_workers, pin_memory=True)               \n",
    "\n",
    "    if params['balance_classes'] == 12 or params['balance_classes'] == 13:\n",
    "        strat_sampler = utils.StratifiedSampler(params)\n",
    "        modelVars['dataloader_trainInd'] = DataLoader(dataset_train, batch_size=params['batchSize'], sampler=strat_sampler, num_workers=num_workers, pin_memory=True) \n",
    "    else:\n",
    "        modelVars['dataloader_trainInd'] = DataLoader(dataset_train, batch_size=params['batchSize'], shuffle=True, num_workers=num_workers, pin_memory=True, drop_last=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(cv):\n",
    "    # Define model \n",
    "    modelVars['model'] = models.getModel(params)() \n",
    "    # Load trained model\n",
    "    if params.get('meta_features',None) is not None:\n",
    "        # Find best checkpoint\n",
    "        files = (params['model_load_path'] / f'CVSet{cv}').glob('/*')\n",
    "        global_steps = np.zeros([len(files)])\n",
    "        for i in range(len(files)):\n",
    "            # Use meta files to find the highest index\n",
    "            if 'best' not in files[i]:\n",
    "                continue\n",
    "            if 'checkpoint' not in files[i]:\n",
    "                continue                \n",
    "            # Extract global step\n",
    "            nums = [int(s) for s in re.findall(r'\\d+',str(files[i]))]\n",
    "            global_steps[i] = nums[-1]\n",
    "        # Create path with maximum global step found\n",
    "        chkPath = params['model_load_path'] / f'CVSet{cv}' / 'checkpoint_best-{int(np.max(global_steps))}.pt'\n",
    "        print(\"Restoring lesion-trained CNN for meta data training: \",chkPath)\n",
    "        # Load\n",
    "        state = torch.load(chkPath)\n",
    "        # Initialize model\n",
    "        curr_model_dict = modelVars['model'].state_dict()\n",
    "        for name, param in state['state_dict'].items():\n",
    "            if isinstance(param, nn.Parameter):\n",
    "                # backwards compatibility for serialized parameters\n",
    "                param = param.data\n",
    "            if curr_model_dict[name].shape == param.shape:\n",
    "                curr_model_dict[name].copy_(param)\n",
    "            else:\n",
    "                print(\"not restored\",name,param.shape)  \n",
    "\n",
    "    if 'Dense' in params['model_type']:\n",
    "        if params['input_size'][0] != 224:\n",
    "            modelVars['model'] = utils.modify_densenet_avg_pool(modelVars['model'])\n",
    "        num_ftrs = modelVars['model'].classifier.in_features\n",
    "        modelVars['model'].classifier = nn.Linear(num_ftrs, params['numClasses'])\n",
    "        #print(modelVars['model'])\n",
    "    elif 'dpn' in params['model_type']:\n",
    "        num_ftrs = modelVars['model'].classifier.in_channels\n",
    "        modelVars['model'].classifier = nn.Conv2d(num_ftrs,params['numClasses'],[1,1])\n",
    "    elif 'efficient' in params['model_type']:\n",
    "        # Do nothing, output is prepared\n",
    "        num_ftrs = modelVars['model']._fc.in_features\n",
    "        modelVars['model']._fc = nn.Linear(num_ftrs, params['numClasses'])    \n",
    "    elif 'wsl' in params['model_type']:\n",
    "        num_ftrs = modelVars['model'].fc.in_features\n",
    "        modelVars['model'].fc = nn.Linear(num_ftrs, params['numClasses'])          \n",
    "    else:\n",
    "        num_ftrs = modelVars['model'].last_linear.in_features\n",
    "        modelVars['model'].last_linear = nn.Linear(num_ftrs, params['numClasses'])    \n",
    "    # Take care of meta case\n",
    "    if params.get('meta_features',None) is not None:\n",
    "        # freeze cnn first\n",
    "        if params['freeze_cnn']:\n",
    "            # deactivate all\n",
    "            for param in modelVars['model'].parameters():\n",
    "                param.requires_grad = False            \n",
    "            if 'efficient' in params['model_type']:\n",
    "                # Activate fc\n",
    "                for param in modelVars['model']._fc.parameters():\n",
    "                    param.requires_grad = True\n",
    "            elif 'wsl' in params['model_type']:\n",
    "                # Activate fc\n",
    "                for param in modelVars['model'].fc.parameters():\n",
    "                    param.requires_grad = True\n",
    "            else:\n",
    "                # Activate fc\n",
    "                for param in modelVars['model'].last_linear.parameters():\n",
    "                    param.requires_grad = True                                \n",
    "        else:\n",
    "            # mark cnn parameters\n",
    "            for param in modelVars['model'].parameters():\n",
    "                param.is_cnn_param = True\n",
    "            # unmark fc\n",
    "            for param in modelVars['model']._fc.parameters():\n",
    "                param.is_cnn_param = False                              \n",
    "        # modify model\n",
    "        modelVars['model'] = models.modify_meta(params,modelVars['model'])  \n",
    "        # Mark new parameters\n",
    "        for param in modelVars['model'].parameters():\n",
    "            if not hasattr(param, 'is_cnn_param'):\n",
    "                param.is_cnn_param = False                 \n",
    "    # multi gpu support\n",
    "    if params['numGPUs'] > 1:\n",
    "        modelVars['model'] = nn.DataParallel(modelVars['model']) \n",
    "    modelVars['model'] = modelVars['model'].cuda()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_loss():\n",
    "    class_weights = params['class_weights']\n",
    "    # Loss, with class weighting\n",
    "    if params.get('focal_loss',False):\n",
    "        modelVars['criterion'] = utils.FocalLoss(alpha=class_weights.tolist())\n",
    "    elif params['balance_classes'] == 2:\n",
    "        #modelVars['criterion'] = nn.BCEWithLogitsLoss(weight=torch.cuda.FloatTensor(class_weights.astype(np.float32)))\n",
    "        modelVars['criterion'] = nn.CrossEntropyLoss(weight=torch.cuda.FloatTensor(class_weights.astype(np.float32)))\n",
    "    elif params['balance_classes'] == 3 or params['balance_classes'] == 0 or params['balance_classes'] == 12:\n",
    "        modelVars['criterion'] = nn.CrossEntropyLoss()\n",
    "    elif params['balance_classes'] == 8:\n",
    "        modelVars['criterion'] = nn.CrossEntropyLoss(reduce=False)\n",
    "    elif params['balance_classes'] == 6 or params['balance_classes'] == 7:\n",
    "        modelVars['criterion'] = nn.CrossEntropyLoss(weight=torch.cuda.FloatTensor(class_weights.astype(np.float32)),reduce=False)\n",
    "    elif params['balance_classes'] == 10:\n",
    "        modelVars['criterion'] = utils.FocalLoss(params['numClasses'])\n",
    "    elif params['balance_classes'] == 11:\n",
    "        modelVars['criterion'] = utils.FocalLoss(params['numClasses'],alpha=torch.cuda.FloatTensor(class_weights.astype(np.float32)))\n",
    "    else:\n",
    "        modelVars['criterion'] = nn.CrossEntropyLoss(weight=torch.cuda.FloatTensor(class_weights.astype(np.float32)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_optimizer():\n",
    "    if params.get('meta_features',None) is not None:\n",
    "        if params['freeze_cnn']:\n",
    "            modelVars['optimizer'] = optim.AdamW(filter(lambda p: p.requires_grad, modelVars['model'].parameters()), lr=params['learning_rate_meta'])\n",
    "            # sanity check\n",
    "            for param in filter(lambda p: p.requires_grad, modelVars['model'].parameters()):\n",
    "                print(param.name,param.shape)\n",
    "        else:\n",
    "            modelVars['optimizer'] = optim.AdamW([\n",
    "                                                {'params': filter(lambda p: not p.is_cnn_param, modelVars['model'].parameters()), 'lr': params['learning_rate_meta']},\n",
    "                                                {'params': filter(lambda p: p.is_cnn_param, modelVars['model'].parameters()), 'lr': params['learning_rate']}\n",
    "                                                ], lr=params['learning_rate'])\n",
    "    else:\n",
    "        modelVars['optimizer'] = optim.AdamW(modelVars['model'].parameters(), lr=params['learning_rate'])\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "#     modelVars['scheduler'] = lr_scheduler.StepLR(modelVars['optimizer'], step_size=params['lowerLRAfter'], gamma=1/np.float32(params['LRstep']))\n",
    "    \n",
    "#     modelVars['scheduler'] = lr_scheduler.OneCycleLR(modelVars['optimizer'], \n",
    "#                                                      max_lr=params['learning_rate'],\n",
    "#                                                      epochs=params['training_steps'],\n",
    "#                                                      steps_per_epoch=params['len_train']//params['batchSize'])\n",
    "    \n",
    "    modelVars['scheduler'] = lr_scheduler.ReduceLROnPlateau(modelVars['optimizer'], mode='max',\n",
    "                                                           factor=0.1, patience=3, verbose=True, \n",
    "                                                           threshold=0.0001, threshold_mode='rel',\n",
    "                                                           cooldown=0, min_lr=0, eps=1e-08)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_checkpoint(load_old):\n",
    "    if load_old:\n",
    "        # Find last, not last best checkpoint\n",
    "        files = list(params['save_dir'].iterdir())\n",
    "        global_steps = np.zeros([len(files)])\n",
    "        for i, file in enumerate(files):\n",
    "            # Use meta files to find the highest index\n",
    "            if 'best' in str(file):\n",
    "                continue\n",
    "            if 'checkpoint-' not in str(file):\n",
    "                continue                \n",
    "            # Extract global step\n",
    "            nums = [int(s) for s in re.findall(r'\\d+',str(file))]\n",
    "            global_steps[i] = nums[-1]\n",
    "        # Create path with maximum global step found\n",
    "        chkPath = params['save_dir'] / f'checkpoint-{int(np.max(global_steps))}.pt'\n",
    "        print(\"Restoring: \",chkPath)\n",
    "        # Load\n",
    "        state = torch.load(chkPath)\n",
    "        # Initialize model and optimizer\n",
    "        modelVars['model'].load_state_dict(state['state_dict'])\n",
    "        modelVars['optimizer'].load_state_dict(state['optimizer'])     \n",
    "        start_epoch = state['epoch']+1\n",
    "        params['valBest'] = state.get('valBest',1000)\n",
    "        params['lastBestInd'] = state.get('lastBestInd',int(np.max(global_steps)))\n",
    "    else:\n",
    "        start_epoch = 1\n",
    "        params['lastBestInd'] = -1\n",
    "        # Track metrics for saving best model\n",
    "        params['valBest'] = 1000\n",
    "\n",
    "    return start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn():\n",
    "    modelVars['model'].train()\n",
    "    \n",
    "    train_targets=[]\n",
    "    train_outputs=[]\n",
    "    \n",
    "    # Num batches\n",
    "    numBatchesTrain = int(math.floor(len(params['trainInd'])/params['batchSize']))   \n",
    "    \n",
    "    for j, (inputs, labels, indices) in tqdm(enumerate(modelVars['dataloader_trainInd']), total=numBatchesTrain):    \n",
    "        # Run optimization        \n",
    "        if params.get('meta_features',None) is not None: \n",
    "            inputs[0] = inputs[0].cuda()\n",
    "            inputs[1] = inputs[1].cuda()\n",
    "        else:\n",
    "            inputs = inputs.cuda()\n",
    "        labels = labels.cuda()        \n",
    "        # zero the parameter gradients\n",
    "        modelVars['optimizer'].zero_grad()             \n",
    "        # forward\n",
    "        with torch.set_grad_enabled(True):             \n",
    "            if params.get('aux_classifier',False):\n",
    "                outputs, outputs_aux = modelVars['model'](inputs) \n",
    "                loss1 = modelVars['criterion'](outputs, labels)\n",
    "                labels_aux = labels.repeat(params['multiCropTrain'])\n",
    "                loss2 = modelVars['criterion'](outputs_aux, labels_aux) \n",
    "                loss = loss1 + params['aux_classifier_loss_fac']*loss2     \n",
    "            else:               \n",
    "                outputs = modelVars['model'](inputs)     \n",
    "                loss = modelVars['criterion'](outputs, labels)\n",
    "            # backward + optimize only if in training phase\n",
    "            loss.backward()\n",
    "            modelVars['optimizer'].step()\n",
    "        \n",
    "        train_targets.extend(labels.cpu().detach().numpy().astype(int).tolist())\n",
    "        train_outputs.extend(outputs)\n",
    "            \n",
    "        \n",
    "    return loss.item(),train_outputs,train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(cv, step):\n",
    "    \n",
    "    # Get metrics\n",
    "    loss, accuracy, sensitivity, specificity, conf_matrix, f1, auc, waccuracy, predictions, targets, _ = getErrClassification_mgpu(params, eval_set, modelVars)\n",
    "    # Save in mat\n",
    "    save_dict['loss'].append(loss)\n",
    "    save_dict['acc'].append(accuracy)\n",
    "    save_dict['wacc'].append(waccuracy)\n",
    "    save_dict['auc'].append(auc)\n",
    "    save_dict['sens'].append(sensitivity)\n",
    "    save_dict['spec'].append(specificity)\n",
    "    save_dict['f1'].append(f1)\n",
    "    save_dict['step_num'].append(step)\n",
    "    if os.path.isfile(params['save_dir'] / f'progression_{eval_set}.mat'):\n",
    "        os.remove(params['save_dir'] / f'progression_{eval_set}.mat')                \n",
    "    io.savemat(str(params['save_dir'] / f'progression_{eval_set}.mat'),save_dict)                \n",
    "    eval_metric = -np.mean(waccuracy)\n",
    "    # Check if we have a new best value\n",
    "    if eval_metric < params['valBest']:\n",
    "        params['valBest'] = eval_metric\n",
    "        if params['classification']:\n",
    "            allData['f1Best'][cv] = f1\n",
    "            allData['sensBest'][cv] = sensitivity\n",
    "            allData['specBest'][cv] = specificity\n",
    "            allData['accBest'][cv] = accuracy\n",
    "            allData['waccBest'][cv] = waccuracy\n",
    "            allData['aucBest'][cv] = auc\n",
    "        oldBestInd = params['lastBestInd']\n",
    "        params['lastBestInd'] = step\n",
    "        allData['convergeTime'][cv] = step\n",
    "        # Save best predictions\n",
    "        allData['bestPred'][cv] = predictions\n",
    "        allData['targets'][cv] = targets\n",
    "        # Write to File\n",
    "        with open(params['save_dir_base'] / 'CV.pkl', 'wb') as f:\n",
    "            pickle.dump(allData, f, pickle.HIGHEST_PROTOCOL)                 \n",
    "        # Delte previously best model\n",
    "        if (params['save_dir'] / f'checkpoint_best-{oldBestInd}.pt').is_file():\n",
    "            (params['save_dir'] / f'checkpoint_best-{oldBestInd}.pt').unlink()\n",
    "        # Save currently best model\n",
    "        state = {'epoch': step, 'valBest': params['valBest'], 'lastBestInd': params['lastBestInd'], 'state_dict': modelVars['model'].state_dict(),'optimizer': modelVars['optimizer'].state_dict()}\n",
    "        torch.save(state, params['save_dir'] / f'checkpoint_best-{step}.pt')\n",
    "        \n",
    "    # If its not better, just save it delete the last checkpoint if it is not current best one\n",
    "    # Save current model\n",
    "    state = {'epoch': step, 'valBest': params['valBest'], 'lastBestInd': params['lastBestInd'], 'state_dict': modelVars['model'].state_dict(),'optimizer': modelVars['optimizer'].state_dict()}\n",
    "    torch.save(state, params['save_dir'] / f'checkpoint-{step}.pt')                           \n",
    "    # Delete last one\n",
    "    if step == params['display_step']:\n",
    "        lastInd = 1\n",
    "    else:\n",
    "        lastInd = step-params['display_step']\n",
    "    if (params['save_dir'] / f'checkpoint-{lastInd}.pt').is_file():\n",
    "        (params['save_dir'] / f'checkpoint-{lastInd}.pt').unlink()\n",
    "        \n",
    "    return loss.item(),predictions,targets  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV set 0\n",
      "cuda:0\n",
      "Current class weights with extra [0.55050505 5.45      ]\n",
      "len im path 102996\n",
      "CP (102996, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "Start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/2289 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 1/2289 [00:00<16:09,  2.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 2/2289 [00:00<12:42,  3.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 3/2289 [00:00<10:36,  3.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 4/2289 [00:00<08:46,  4.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 5/2289 [00:00<07:43,  4.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 6/2289 [00:01<06:46,  5.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 7/2289 [00:01<06:45,  5.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 8/2289 [00:01<06:01,  6.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 9/2289 [00:01<06:34,  5.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 10/2289 [00:01<05:57,  6.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 11/2289 [00:01<06:07,  6.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 12/2289 [00:01<05:38,  6.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 13/2289 [00:02<06:00,  6.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 14/2289 [00:02<05:31,  6.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 15/2289 [00:02<05:34,  6.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 16/2289 [00:02<05:16,  7.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 17/2289 [00:02<05:40,  6.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 18/2289 [00:02<05:19,  7.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 19/2289 [00:03<06:00,  6.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 20/2289 [00:03<05:34,  6.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 21/2289 [00:03<06:00,  6.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 22/2289 [00:03<05:28,  6.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 23/2289 [00:03<06:11,  6.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 24/2289 [00:03<05:39,  6.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 25/2289 [00:03<05:40,  6.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 26/2289 [00:04<05:19,  7.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 27/2289 [00:04<05:29,  6.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 28/2289 [00:04<05:10,  7.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▏         | 29/2289 [00:04<05:47,  6.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▏         | 30/2289 [00:04<05:24,  6.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▏         | 31/2289 [00:04<05:40,  6.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▏         | 32/2289 [00:04<05:16,  7.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▏         | 33/2289 [00:05<05:51,  6.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▏         | 34/2289 [00:05<05:27,  6.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 35/2289 [00:05<05:55,  6.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 36/2289 [00:05<05:27,  6.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 37/2289 [00:05<05:47,  6.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 38/2289 [00:05<05:25,  6.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 39/2289 [00:06<05:43,  6.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 40/2289 [00:06<05:18,  7.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 41/2289 [00:06<05:52,  6.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 42/2289 [00:06<05:25,  6.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 43/2289 [00:06<05:34,  6.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 44/2289 [00:06<05:09,  7.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 45/2289 [00:06<05:34,  6.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 46/2289 [00:07<05:16,  7.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 47/2289 [00:07<05:47,  6.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 48/2289 [00:07<05:24,  6.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 49/2289 [00:07<05:44,  6.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 50/2289 [00:07<05:19,  7.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 51/2289 [00:07<05:47,  6.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 52/2289 [00:07<05:18,  7.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 53/2289 [00:08<05:52,  6.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 54/2289 [00:08<05:27,  6.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 55/2289 [00:08<05:36,  6.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 56/2289 [00:08<05:08,  7.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 57/2289 [00:08<06:00,  6.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 58/2289 [00:08<05:31,  6.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 59/2289 [00:08<05:35,  6.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 60/2289 [00:09<05:14,  7.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 61/2289 [00:09<05:53,  6.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 62/2289 [00:09<05:25,  6.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 63/2289 [00:09<05:44,  6.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 64/2289 [00:09<05:20,  6.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-5d5190934732>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtk0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training_steps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtk0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-3259ead5ea4e>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# backward + optimize only if in training phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mmodelVars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mtrain_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Take care of CV\n",
    "if params.get('cv_subset',None) is not None:\n",
    "    cv_set = params['cv_subset']\n",
    "else:\n",
    "    cv_set = range(params['numCV'])\n",
    "for cv in cv_set:      \n",
    "    already_trained, load_old = check_cv(cv)    \n",
    "    if already_trained:\n",
    "        continue        \n",
    "    print(\"CV set\",cv)\n",
    "    # Reset model graph \n",
    "    importlib.reload(models)\n",
    "    # Collect model variables\n",
    "    modelVars = {}\n",
    "    #print(\"here\")\n",
    "    modelVars['device'] = device\n",
    "    print(modelVars['device'])\n",
    "    # Save training progress in here\n",
    "    save_dict = {}\n",
    "    save_dict['acc'] = []\n",
    "    save_dict['loss'] = []\n",
    "    save_dict['wacc'] = []\n",
    "    save_dict['auc'] = []\n",
    "    save_dict['sens'] = []\n",
    "    save_dict['spec'] = []\n",
    "    save_dict['f1'] = []\n",
    "    save_dict['step_num'] = []\n",
    "    if params['print_trainerr']:\n",
    "        save_dict_train = {}\n",
    "        save_dict_train['acc'] = []\n",
    "        save_dict_train['loss'] = []\n",
    "        save_dict_train['wacc'] = []\n",
    "        save_dict_train['auc'] = []\n",
    "        save_dict_train['sens'] = []\n",
    "        save_dict_train['spec'] = []\n",
    "        save_dict_train['f1'] = []\n",
    "        save_dict_train['step_num'] = []        \n",
    "    # Potentially calculate setMean to subtract\n",
    "    if params['subtract_set_mean'] == 1:\n",
    "        params['setMean'] = np.mean(params['images_means'][params['trainInd'],:],(0))\n",
    "        print(\"Set Mean\",params['setMean']) \n",
    "    \n",
    "    # Meta scaler\n",
    "    if params.get('meta_features',None) is not None and params['scale_features']:\n",
    "        params['feature_scaler_meta'] = sklearn.preprocessing.StandardScaler().fit(params['meta_array'][params['trainInd'],:])  \n",
    "        print(\"scaler mean\",params['feature_scaler_meta'].mean_,\"var\",params['feature_scaler_meta'].var_) \n",
    "    \n",
    "    params['trainSetState'] = 'train'\n",
    "    balance_classes()\n",
    "    get_loaders()\n",
    "    initialize_model(cv)\n",
    "    define_loss()\n",
    "    define_optimizer()\n",
    "\n",
    "    # Define softmax\n",
    "    modelVars['softmax'] = nn.Softmax(dim=1)\n",
    "\n",
    "    # loading from checkpoint\n",
    "    start_epoch = restore_checkpoint(load_old)\n",
    "        \n",
    "    # History dictionary to store everything\n",
    "    history = {\n",
    "            'train_history_loss': [],\n",
    "            'train_history_auc': [],\n",
    "            'val_history_loss': [],\n",
    "            'val_history_auc': [],\n",
    "             }\n",
    "    \n",
    "    # Run training\n",
    "    start_time = time.time()\n",
    "    print(\"Start training...\")\n",
    "    \n",
    "    tk0 = tqdm(range(start_epoch, params['training_steps']+1))\n",
    "    for step in tk0: \n",
    "        train_loss,train_out,train_targets = train_fn()\n",
    "        val_loss, outputs, targets = eval_fn(cv, step)\n",
    "        \n",
    "        duration = time.time() - start_time\n",
    "        print(\"Config:\",OUT)\n",
    "        print('Fold: %d Epoch: %d/%d (%d h %d m %d s)' % (cv,step,params['training_steps'], int(duration/3600), int(np.mod(duration,3600)/60), int(np.mod(np.mod(duration,3600),60))) + time.strftime(\"%d.%m.-%H:%M:%S\", time.localtime()))\n",
    "        \n",
    "        tk0.set_postfix(Train_Loss=train_loss, \n",
    "                        Valid_Loss=val_loss, \n",
    "                        ACC=save_dict['acc'],\n",
    "                        F1=save_dict['f1'],\n",
    "                        AUC=save_dict['auc'],\n",
    "                        WAUC=save_dict['wauc'], \n",
    "                        Sensitivity=save_dict['sens'], \n",
    "                        Specificity=save_dict['spec'], \n",
    "                        Best=f\"best WACC: {params['valBest']} at Epoch {params['lastBestInd']}\"\n",
    "                       )\n",
    "        print(\"Confusion Matrix\")\n",
    "        print(conf_matrix)\n",
    "        \n",
    "        modelVars['scheduler'].step(save_dict['auc'])\n",
    "        \n",
    "        history['train_history_loss'].append(train_loss)\n",
    "        history['train_history_auc'].append(train_auc)\n",
    "        history['val_history_loss'].append(val_loss)\n",
    "        history['val_history_auc'].append(auc_score)\n",
    "        \n",
    "    utils.print_history(cv,history,num_epochs=step+1)\n",
    "\n",
    "         \n",
    "                \n",
    "    # Free everything in modelvars\n",
    "    modelVars.clear()\n",
    "    # After CV Training: print CV results and save them\n",
    "    print(\"Best F1:\",allData['f1Best'][cv])\n",
    "    print(\"Best Sens:\",allData['sensBest'][cv])\n",
    "    print(\"Best Spec:\",allData['specBest'][cv])\n",
    "    print(\"Best Acc:\",allData['accBest'][cv])\n",
    "    print(\"Best Per Class Accuracy:\",allData['waccBest'][cv])\n",
    "    print(\"Best Weighted Acc:\",np.mean(allData['waccBest'][cv]))\n",
    "    print(\"Best AUC:\",allData['aucBest'][cv])\n",
    "    print(\"Best Mean AUC:\",np.mean(allData['aucBest'][cv]))    \n",
    "    print(\"Convergence Steps:\",allData['convergeTime'][cv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "params['save_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
